{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedindata = \"vivek.json\"\n",
    "filepath = \"Json/New data/\"+linkedindata\n",
    "with open(filepath, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# print(data[\"skills\"])\n",
    "# prompt = \"Write a cover letter to \" + manager_name + \" from \" + \\\n",
    "#     employee_name + \" for position at \" + compnay_name\n",
    "# + \". I am excited about the opportunity to join a company that \" + \\\n",
    "#     company_description + \"\\n\" \"I am currently working as \" + occupation + +summary+\", with a total of \" + \\\n",
    "#     str(total_years_experience) + \" years of experience. I have \" + \\\n",
    "#     sub_experience + \" experience in \" + description_of_experience + \"\\n\"\n",
    "# \"My skills include: \" + skills + \". I have completed my education in \" + education + \\\n",
    "#     \" with a major in \" + field + \" from \" + college_name + \\\n",
    "#     \" where I studied \" + course_name + \"\\n\" \"I am based in \" + city + \", \" + \\\n",
    "#     state + \", \" + country + \" and my email address is \" + email + \"\\n\"\n",
    "data[\"data\"][\"skills\"]\n",
    "# data[\"data\"][\"first_name\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For get all the data from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "skills=\"\"\n",
    "for i in range(len(data[\"data\"][\"skills\"])):\n",
    "    skills_data=data[\"data\"][\"skills\"][i]\n",
    "    if i == 0:\n",
    "        skills += \" \" + skills_data\n",
    "    else:\n",
    "        skills += \", \" + skills_data\n",
    "    \n",
    "print(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "languages = \"\"\n",
    "for i in range(len(data[\"data\"][\"languages\"])):\n",
    "    languages_data = data[\"data\"][\"languages\"][i]\n",
    "    if i == 0:\n",
    "        languages += \"    \" + languages_data\n",
    "    else:\n",
    "        languages += \", \" + languages_data\n",
    "\n",
    "print(languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 138, 'user_id_id': 3, 'starts_at': '2020-12-01T00:00:00Z', 'ends_at': '2021-05-31T00:00:00Z', 'company': 'Maxgen technologies Pvt. Ltd.', 'title': 'Machine Learning Intern', 'description': None, 'location': None}\n"
     ]
    }
   ],
   "source": [
    "print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "\n",
      "    starts at: 2022-07-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Machine Learning Engineer,\n",
      "    description: None,\n",
      "    location: India.\n",
      "\n",
      "    starts at: 2021-12-01T00:00:00Z,\n",
      "    Ends at: 2022-07-31T00:00:00Z,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Machine Learning Intern,\n",
      "    description: None,\n",
      "    location: Ahmedabad, Gujarat, India.\n",
      "\n",
      "    starts at: 2020-12-01T00:00:00Z,\n",
      "    Ends at: 2021-05-31T00:00:00Z,\n",
      "    Company: Maxgen technologies Pvt. Ltd.,\n",
      "    Title: Machine Learning Intern,\n",
      "    description: None,\n",
      "    location: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_experiences = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    print(j)\n",
    "    # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j])\n",
    "\n",
    "    # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at'])\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "    location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "    user_experiences_data = \"    starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Company: \"+str(company) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    description: \"+str(description) +\\\n",
    "        \",\\n\"\"    location: \"+str(location)+\".\\n\"\n",
    "\n",
    "        # print(user_experiences)\n",
    "    user_experiences +=  \"\\n\"+user_experiences_data\n",
    "\n",
    "print(user_experiences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "\n",
      "    starts at: 2022-07-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Machine Learning Engineer,\n",
      "    description: None,\n",
      "    location: India.\n",
      "\n",
      "    starts at: 2021-12-01T00:00:00Z,\n",
      "    Ends at: 2022-07-31T00:00:00Z,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Machine Learning Intern,\n",
      "    description: None,\n",
      "    location: Ahmedabad, Gujarat, India.\n",
      "\n",
      "    starts at: 2020-12-01T00:00:00Z,\n",
      "    Ends at: 2021-05-31T00:00:00Z,\n",
      "    Company: Maxgen technologies Pvt. Ltd.,\n",
      "    Title: Machine Learning Intern,\n",
      "    description: None,\n",
      "    location: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_experiences = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    \n",
    "    print(j)\n",
    "    # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j])\n",
    "    # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at'])\n",
    "\n",
    "    if j<4:\n",
    "        starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "        ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "        company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "        title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "        description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "        location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "        user_experiences_data = \"    starts at: \"+str(starts_at) +\\\n",
    "            \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "            \",\\n\"\"    Company: \"+str(company) +\\\n",
    "            \",\\n\"\"    Title: \"+str(title) +\\\n",
    "            \",\\n\"\"    description: \"+str(description) +\\\n",
    "            \",\\n\"\"    location: \"+str(location)+\".\\n\"\n",
    "\n",
    "        # print(user_experiences)\n",
    "        user_experiences += \"\\n\"+user_experiences_data\n",
    "print(user_experiences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Starts at: 2015-01-01T00:00:00Z,\n",
      "    Ends at: 2019-12-31T00:00:00Z,\n",
      "    Field of study: Computer Engineering,\n",
      "    Degree name: Bachelor's degree,\n",
      "    School: L.D. College of Engineering.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usereducation = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usereducation\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['ends_at']\n",
    "    field_of_study = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['field_of_study']\n",
    "    degree_name = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['degree_name']\n",
    "    school = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['school']\n",
    "    \n",
    "    usereducation_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Field of study: \"+str(field_of_study) +\\\n",
    "        \",\\n\"\"    Degree name: \"+str(degree_name) +\\\n",
    "        \",\\n\"\"    School: \"+str(school) +\".\\n\"\n",
    "\n",
    "    # print(usereducation)\n",
    "    usereducation += \"\\n\"+usereducation_data\n",
    "\n",
    "print(usereducation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentorganisations = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"])):\n",
    "    org_name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['org_name']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentorganisations_data = \"    Organisation name: \"+str(org_name) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentorganisations)\n",
    "    useraccomplishmentorganisations += \"\\n\"+useraccomplishmentorganisations_data\n",
    "\n",
    "print(useraccomplishmentorganisations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "\n",
      "    Title: AI Powered Resume Screener,\n",
      "    Description: Managed the research & development of a system, built for large talent acquisition firms, that eases the work of hiring team by scoring every resume in the system for a given job description. It also helps the recruiter understand why the selected candidates are the best match for their job..\n",
      "\n",
      "    Title: Bidirectional Attention Flow for Machine Comprehension,\n",
      "    Description: Implemented the research paper Bidirectional Attention Flow for Machine Comprehension in Keras from scratch. The project aims at extracting answers for a specific question from a given article..\n",
      "\n",
      "    Title: Entropy,\n",
      "    Description: Leading the development of Entropy, an algorithmic trading platform for cryptocurrency. Planning the features of initial release by doing necessary research and understanding complexities of tasks; and guiding the team in the right direction..\n",
      "\n",
      "    Title: Fraud Detection in Bitcoin.com Casino,\n",
      "    Description: Bitcoin.com has its official online casinos where people can play using cryptocurrencies. Built a fraud detection algorithm, using unsupervised learning, that is capable of monitoring withdrawals from the casino and raising alerts when potential fraudulent activity is detected..\n",
      "\n",
      "    Title: GMR Energy Market Price Prediction,\n",
      "    Description: Built a system that is capable of predicting the price at which energy will be traded at Indian Energy Exchange. Analyzed the time series data from past 3 years and built an ensemble of 3 different model architectures that is able to provide the best accuracy of 83% on average with a tolerance of 10% and maximum being 93%..\n",
      "\n",
      "    Title: H+Tree,\n",
      "    Description: H+Tree is research work which aims at optimizing the internal B+Tree module of database storage systems in order to have a new database storage system which is 2x faster and more storage efficient..\n",
      "\n",
      "    Title: Handwrittern Sanskrit OCR,\n",
      "    Description: Built an OCR system for Handwritten Ancient Indian Language (Sanskrit) from the 1000s. The data was highly complex in nature with no spacing and punctuations, with manual corrections, and designs within pages. The system encompasses four different modules which identifies lines, OCRs a line, combines and orders the lines and performs text correction..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentprojects = \"\"\n",
    "print(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]))\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentprojects_data = \"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    useraccomplishmentprojects += \"\\n\"+useraccomplishmentprojects_data\n",
    "\n",
    "print(useraccomplishmentprojects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uservolunteerwork = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['ends_at']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['description']\n",
    "    cause = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['cause']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['company']\n",
    "\n",
    "    uservolunteerwork_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) +\\\n",
    "        \",\\n\"\"    Cause: \"+str(cause) +\\\n",
    "        \",\\n\"\"    Company: \"+str(company) + \".\\n\"\n",
    "\n",
    "    # print(uservolunteerwork)\n",
    "    uservolunteerwork += \"\\n\"+uservolunteerwork_data\n",
    "\n",
    "print(uservolunteerwork)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usercertifications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usercertifications\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['starts_at']\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['name']\n",
    "    authority = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['authority']\n",
    "   \n",
    "\n",
    "    usercertifications_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Name: \"+str(name) +\\\n",
    "        \",\\n\"\"    Authority: \"+str(authority) +\".\\n\"\n",
    "\n",
    "    # print(usercertifications)\n",
    "    usercertifications += \"\\n\"+usercertifications_data\n",
    "\n",
    "print(usercertifications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentpublications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"])):\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['name']\n",
    "    publisher = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['publisher']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentpublications_data = \"    Name: \"+str(name) +\\\n",
    "        \",\\n\"\"    Publisher: \"+str(publisher) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentpublications)\n",
    "    useraccomplishmentpublications += \"\\n\"+useraccomplishmentpublications_data\n",
    "\n",
    "print(useraccomplishmentpublications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmenthonorsawards = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['title']\n",
    "    issuer = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['issuer']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['description']\n",
    "\n",
    "    useraccomplishmenthonorsawards_data = \"    title: \"+str(title) +\\\n",
    "        \",\\n\"\"    issuer: \"+str(issuer) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmenthonorsawards)\n",
    "    useraccomplishmenthonorsawards += \"\\n\"+useraccomplishmenthonorsawards_data\n",
    "\n",
    "print(useraccomplishmenthonorsawards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_name = str(data[\"data\"][\"first_name\"])\n",
    "last_name = data[\"data\"][\"last_name\"]\n",
    "Occupation = data[\"data\"][\"occupation\"]\n",
    "Email = data[\"data\"][\"email\"]\n",
    "Summary = data[\"data\"][\"summary\"]\n",
    "Country_full_name = data[\"data\"][\"country_full_name\"]\n",
    "City = data[\"data\"][\"city\"]\n",
    "state = data[\"data\"][\"state\"]\n",
    "# Languages = data[\"data\"][\"languages\"]\n",
    "Languages = languages\n",
    "# skills = data[\"data\"][\"skills\"]\n",
    "skills = skills\n",
    "\n",
    "# User_experiences = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"]\n",
    "User_experiences = user_experiences\n",
    "\n",
    "# User_education = data[\"data\"][\"user_carrier_data\"][\"usereducation\"]\n",
    "User_education = usereducation\n",
    "\n",
    "# User_accomplishment_organisations = data[\"data\"][\n",
    "    # \"user_carrier_data\"][\"useraccomplishmentorganisations\"]\n",
    "User_accomplishment_organisations = useraccomplishmentorganisations\n",
    "\n",
    "# User_accomplishment_projects = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]\n",
    "User_accomplishment_projects = useraccomplishmentprojects\n",
    "\n",
    "# User_volunteer_work = User_certifications = data[\n",
    "#     \"data\"][\"user_carrier_data\"][\"uservolunteerwork\"]\n",
    "User_volunteer_work = uservolunteerwork\n",
    "\n",
    "# User_certifications = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"]\n",
    "User_certifications = usercertifications\n",
    "\n",
    "# User_accomplishment_publications = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmentpublications\"]\n",
    "User_accomplishment_publications = useraccomplishmentpublications\n",
    "\n",
    "# User_accomplishment_honors_awards = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmenthonorsawards\"]\n",
    "User_accomplishment_honors_awards = useraccomplishmenthonorsawards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_details = \"Profile details:\\n\" \\\n",
    "    \"Name: \"+str(First_name) + \" \"+str(last_name) + \"\\n\"\\\n",
    "    \"Occupation: \"+str(Occupation) + \"\\n\"\\\n",
    "    \"Email: \"+str(Email) + \"\\n\"\\\n",
    "    \"Summary: \"+str(Summary) + \"\\n\"\\\n",
    "    \"Country: \"+str(Country_full_name) + \"\\n\"\\\n",
    "    \"City: \"+str(City) + \"\\n\"\\\n",
    "    \"state: \"+str(state) + \"\\n\"\\\n",
    "    \"Languages: \"+str(Languages) + \"\\n\"\\\n",
    "    \"skills: \"+str(skills) + \"\\n\"\\\n",
    "    \"experiences: \"+str(User_experiences) + \"\\n\"\\\n",
    "    \"education: \"+str(User_education) + \"\\n\"\\\n",
    "    \"accomplishment_organisations: \"+str(User_accomplishment_organisations) + \"\\n\"\\\n",
    "    \"projects: \"+str(User_accomplishment_projects) + \"\\n\"\\\n",
    "    \"Volunteer work: \"+str(User_volunteer_work) + \"\\n\"\\\n",
    "    \"certifications: \"+str(User_certifications) + \"\\n\"\\\n",
    "    \"publications: \"+str(User_accomplishment_publications) + \"\\n\"\\\n",
    "    \"honors_awards: \"+str(User_accomplishment_honors_awards) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Profile details:\\nName: Kadam Parikh\\nOccupation: Lead Software Engineer (Machine Learning) at F(x) Data Labs\\nEmail: kadam@htree.plus\\nSummary: Technical Lead with 4+ years of experience in the field of Machine Learning and Software Engineering.   \\n\\nI love to build practical systems irrespective of their kind, but my preference lies in systems that can utilize the power of AI.\\n\\nInterested Domain: FinTech\\nCountry: India\\nCity: Ahmedabad\\nstate: Gujarat\\nLanguages: \\nskills: \\nexperiences: \\n    starts at: 2021-12-01T00:00:00Z,\\n    Ends at: None,\\n    Company: F(x) Data Labs,\\n    Title: Lead Software Engineer (Machine Learning),\\n    description: Key Achievements:\\n- Optimized the project workflows at the workplace.\\n- Built an AI based resume screener for large talent acquisition teams.\\n- Leading teams of size ~12 across 3 different projects simultaneously.\\n- Learning project management skills.,\\n    location: Ahmedabad, Gujarat, India.\\n\\n    starts at: 2020-03-01T00:00:00Z,\\n    Ends at: 2021-11-30T00:00:00Z,\\n    Company: F(x) Data Labs,\\n    Title: Software Engineer (Machine Learning),\\n    description: Key Achievements:\\n- Leading the development and planning of an algorithmic trading\\nplatform for cryptocurrency.\\n- Built an accurate Handwritten Ancient Sanskrit Text Recognition\\nSystem for old texts from the 1000s.\\n- Developed an unsupervised algorithm using Random Forests to detect\\nfrauds in Bitcoin Games Casino.\\n- Boosted the accuracy of a time series based Oil Well Anomaly\\nDetection system by 10%.,\\n    location: Ahmedabad, Gujarat.\\n\\n    starts at: 2019-02-01T00:00:00Z,\\n    Ends at: 2020-02-29T00:00:00Z,\\n    Company: F(x) Data Labs,\\n    Title: Associate Software Engineer (Machine Learning),\\n    description: Key Achievements:\\n- Developed H+Tree, a 2x faster data structure as compared to B+Tree.\\n- Implemented a research paper based on Knowledge Graphs and Object\\nDetection.\\n- Mentored new team members at our workplace in Machine Learning.,\\n    location: Ahmedabad, Gujarat, India.\\n\\n    starts at: 2017-01-01T00:00:00Z,\\n    Ends at: 2019-01-31T00:00:00Z,\\n    Company: Blogger Blogspot,\\n    Title: Blogger,\\n    description: Blogging with a view to share knowledge on cyber security to the world. Responsibilities include getting some time out of other work, gaining the knowledge and sharing them to the world in a simple language that makes the subject seem easy. Have wrote many articles (nearly 130) and have achieved a great success with views from all over the world (mostly U.S., Canada, Russia and India). Feedback received for the work is great and total blog views are currently 50000+.,\\n    location: None.\\n\\neducation: \\n    Starts at: 2015-01-01T00:00:00Z,\\n    Ends at: 2019-12-31T00:00:00Z,\\n    Field of study: Computer Engineering,\\n    Degree name: Bachelor's degree,\\n    School: L.D. College of Engineering.\\n\\naccomplishment_organisations: \\nprojects: \\n    Title: AI Powered Resume Screener,\\n    Description: Managed the research & development of a system, built for large talent acquisition firms, that eases the work of hiring team by scoring every resume in the system for a given job description. It also helps the recruiter understand why the selected candidates are the best match for their job..\\n\\n    Title: Bidirectional Attention Flow for Machine Comprehension,\\n    Description: Implemented the research paper Bidirectional Attention Flow for Machine Comprehension in Keras from scratch. The project aims at extracting answers for a specific question from a given article..\\n\\n    Title: Entropy,\\n    Description: Leading the development of Entropy, an algorithmic trading platform for cryptocurrency. Planning the features of initial release by doing necessary research and understanding complexities of tasks; and guiding the team in the right direction..\\n\\n    Title: Fraud Detection in Bitcoin.com Casino,\\n    Description: Bitcoin.com has its official online casinos where people can play using cryptocurrencies. Built a fraud detection algorithm, using unsupervised learning, that is capable of monitoring withdrawals from the casino and raising alerts when potential fraudulent activity is detected..\\n\\n    Title: GMR Energy Market Price Prediction,\\n    Description: Built a system that is capable of predicting the price at which energy will be traded at Indian Energy Exchange. Analyzed the time series data from past 3 years and built an ensemble of 3 different model architectures that is able to provide the best accuracy of 83% on average with a tolerance of 10% and maximum being 93%..\\n\\n    Title: H+Tree,\\n    Description: H+Tree is research work which aims at optimizing the internal B+Tree module of database storage systems in order to have a new database storage system which is 2x faster and more storage efficient..\\n\\n    Title: Handwrittern Sanskrit OCR,\\n    Description: Built an OCR system for Handwritten Ancient Indian Language (Sanskrit) from the 1000s. The data was highly complex in nature with no spacing and punctuations, with manual corrections, and designs within pages. The system encompasses four different modules which identifies lines, OCRs a line, combines and orders the lines and performs text correction..\\n\\nVolunteer work: \\ncertifications: \\npublications: \\nhonors_awards: \\n\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = \"Turing.json\"\n",
    "filepath = \"Json/job_detail/\"+job_file\n",
    "with open(filepath, 'r') as json_file:\n",
    "    job_data = json.load(json_file)\n",
    "\n",
    "job_description = job_data[\"job_description\"]\n",
    "\n",
    "title = job_data[\"title\"]\n",
    "location = str(job_data[\"location\"][\"city\"]) + \",\" + \\\n",
    "    str(job_data[\"location\"][\"region\"])+\",\" + \\\n",
    "    str(job_data[\"location\"][\"country\"])\n",
    "company = job_data[\"company\"][\"name\"]\n",
    "industry = job_data[\"industry\"][0]\n",
    "employment_type = job_data[\"employment_type\"]\n",
    "job_functions = job_data[\"job_functions\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      "     Title: Remote Machine Learning Engineer Jobs\n",
      "    Compnay name: Turing\n",
      "    Location: None,None,India\n",
      "    Industry: Software Development\n",
      "    Job description: An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "**Job Responsibilities:**\n",
      "  \n",
      "\n",
      "  * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "  * Experiment with ML techniques to create and test new program features\n",
      "  * Assist in extending and improving existing ML frameworks and libraries\n",
      "  * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "  * Integrate ML models to end-users and run experiments\n",
      "  * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "**Job Requirements:**\n",
      "  \n",
      "\n",
      "  * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "  * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "  * Must have hands-on experience in Adaptive Learning Systems \n",
      "  * Should be well versed in MEAN and/or MERN stacks\n",
      "  * Expertise in Machine Learning and Artificial Intelligence \n",
      "  * Experience in data science projects and psychometrics is required\n",
      "  * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "    Employment type: Full-time\n",
      "    Job functions: Engineering and Information Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_details = \"Job details:\\n \"\\\n",
    "    \"    Title: \"+str(title) + \"\\n\"\\\n",
    "    \"    Compnay name: \"+str(company) + \"\\n\"\\\n",
    "    \"    Location: \"+str(location) + \"\\n\"\\\n",
    "    \"    Industry: \"+str(industry) + \"\\n\"\\\n",
    "    \"    Job description: \"+str(job_description) + \"\\n\"\\\n",
    "    \"    Employment type: \"+str(employment_type) + \"\\n\"\\\n",
    "    \"    Job functions: \"+str(job_functions) + \"\\n\"\n",
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      "     Title: Remote Machine Learning Engineer Jobs\n",
      "    Compnay name: Turing\n",
      "    Location: None,None,India\n",
      "    Industry: Software Development\n",
      "    Job description: An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "**Job Responsibilities:**\n",
      "  \n",
      "\n",
      "  * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "  * Experiment with ML techniques to create and test new program features\n",
      "  * Assist in extending and improving existing ML frameworks and libraries\n",
      "  * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "  * Integrate ML models to end-users and run experiments\n",
      "  * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "**Job Requirements:**\n",
      "  \n",
      "\n",
      "  * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "  * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "  * Must have hands-on experience in Adaptive Learning Systems \n",
      "  * Should be well versed in MEAN and/or MERN stacks\n",
      "  * Expertise in Machine Learning and Artificial Intelligence \n",
      "  * Experience in data science projects and psychometrics is required\n",
      "  * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "    Employment type: Full-time\n",
      "    Job functions: Engineering and Information Technology\n",
      "\n",
      " Profile details:\n",
      "Name: Kadam Parikh\n",
      "Occupation: Lead Software Engineer (Machine Learning) at F(x) Data Labs\n",
      "Email: kadam@htree.plus\n",
      "Summary: Technical Lead with 4+ years of experience in the field of Machine Learning and Software Engineering.   \n",
      "\n",
      "I love to build practical systems irrespective of their kind, but my preference lies in systems that can utilize the power of AI.\n",
      "\n",
      "Interested Domain: FinTech\n",
      "Country: India\n",
      "City: Ahmedabad\n",
      "state: Gujarat\n",
      "Languages: \n",
      "skills: \n",
      "experiences: \n",
      "    starts at: 2021-12-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Lead Software Engineer (Machine Learning),\n",
      "    description: Key Achievements:\n",
      "- Optimized the project workflows at the workplace.\n",
      "- Built an AI based resume screener for large talent acquisition teams.\n",
      "- Leading teams of size ~12 across 3 different projects simultaneously.\n",
      "- Learning project management skills.,\n",
      "    location: Ahmedabad, Gujarat, India.\n",
      "\n",
      "    starts at: 2020-03-01T00:00:00Z,\n",
      "    Ends at: 2021-11-30T00:00:00Z,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Software Engineer (Machine Learning),\n",
      "    description: Key Achievements:\n",
      "- Leading the development and planning of an algorithmic trading\n",
      "platform for cryptocurrency.\n",
      "- Built an accurate Handwritten Ancient Sanskrit Text Recognition\n",
      "System for old texts from the 1000s.\n",
      "- Developed an unsupervised algorithm using Random Forests to detect\n",
      "frauds in Bitcoin Games Casino.\n",
      "- Boosted the accuracy of a time series based Oil Well Anomaly\n",
      "Detection system by 10%.,\n",
      "    location: Ahmedabad, Gujarat.\n",
      "\n",
      "    starts at: 2019-02-01T00:00:00Z,\n",
      "    Ends at: 2020-02-29T00:00:00Z,\n",
      "    Company: F(x) Data Labs,\n",
      "    Title: Associate Software Engineer (Machine Learning),\n",
      "    description: Key Achievements:\n",
      "- Developed H+Tree, a 2x faster data structure as compared to B+Tree.\n",
      "- Implemented a research paper based on Knowledge Graphs and Object\n",
      "Detection.\n",
      "- Mentored new team members at our workplace in Machine Learning.,\n",
      "    location: Ahmedabad, Gujarat, India.\n",
      "\n",
      "    starts at: 2017-01-01T00:00:00Z,\n",
      "    Ends at: 2019-01-31T00:00:00Z,\n",
      "    Company: Blogger Blogspot,\n",
      "    Title: Blogger,\n",
      "    description: Blogging with a view to share knowledge on cyber security to the world. Responsibilities include getting some time out of other work, gaining the knowledge and sharing them to the world in a simple language that makes the subject seem easy. Have wrote many articles (nearly 130) and have achieved a great success with views from all over the world (mostly U.S., Canada, Russia and India). Feedback received for the work is great and total blog views are currently 50000+.,\n",
      "    location: None.\n",
      "\n",
      "education: \n",
      "    Starts at: 2015-01-01T00:00:00Z,\n",
      "    Ends at: 2019-12-31T00:00:00Z,\n",
      "    Field of study: Computer Engineering,\n",
      "    Degree name: Bachelor's degree,\n",
      "    School: L.D. College of Engineering.\n",
      "\n",
      "accomplishment_organisations: \n",
      "projects: \n",
      "    Title: AI Powered Resume Screener,\n",
      "    Description: Managed the research & development of a system, built for large talent acquisition firms, that eases the work of hiring team by scoring every resume in the system for a given job description. It also helps the recruiter understand why the selected candidates are the best match for their job..\n",
      "\n",
      "    Title: Bidirectional Attention Flow for Machine Comprehension,\n",
      "    Description: Implemented the research paper Bidirectional Attention Flow for Machine Comprehension in Keras from scratch. The project aims at extracting answers for a specific question from a given article..\n",
      "\n",
      "    Title: Entropy,\n",
      "    Description: Leading the development of Entropy, an algorithmic trading platform for cryptocurrency. Planning the features of initial release by doing necessary research and understanding complexities of tasks; and guiding the team in the right direction..\n",
      "\n",
      "    Title: Fraud Detection in Bitcoin.com Casino,\n",
      "    Description: Bitcoin.com has its official online casinos where people can play using cryptocurrencies. Built a fraud detection algorithm, using unsupervised learning, that is capable of monitoring withdrawals from the casino and raising alerts when potential fraudulent activity is detected..\n",
      "\n",
      "    Title: GMR Energy Market Price Prediction,\n",
      "    Description: Built a system that is capable of predicting the price at which energy will be traded at Indian Energy Exchange. Analyzed the time series data from past 3 years and built an ensemble of 3 different model architectures that is able to provide the best accuracy of 83% on average with a tolerance of 10% and maximum being 93%..\n",
      "\n",
      "    Title: H+Tree,\n",
      "    Description: H+Tree is research work which aims at optimizing the internal B+Tree module of database storage systems in order to have a new database storage system which is 2x faster and more storage efficient..\n",
      "\n",
      "    Title: Handwrittern Sanskrit OCR,\n",
      "    Description: Built an OCR system for Handwritten Ancient Indian Language (Sanskrit) from the 1000s. The data was highly complex in nature with no spacing and punctuations, with manual corrections, and designs within pages. The system encompasses four different modules which identifies lines, OCRs a line, combines and orders the lines and performs text correction..\n",
      "\n",
      "Volunteer work: \n",
      "certifications: \n",
      "publications: \n",
      "honors_awards: \n",
      "\n",
      "Write 500 words of a classic job cover letter for provided profile details if job application is done for the above mention job details\n"
     ]
    }
   ],
   "source": [
    "# job_details = \"Job details:\\n \"\n",
    "gpt_prompt = job_details + \"\\n \"+profile_details + \\\n",
    "    \"\\nWrite 500 words of a classic job cover letter for provided profile details if job application is done for the above mention job details\"\n",
    "print(gpt_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------cover letter----------------------\n",
      "\n",
      "\n",
      "Dear Hiring Manager, \n",
      "\n",
      "I am writing in response to your posting for a Remote Machine Learning Engineer job with Turing. As a highly analytical Lead Software Engineer with 4+ years of experience in Machine Learning and software engineering, I can bring my knowledge and expertise to ensure that your ML models are optimized and applied properly. \n",
      "\n",
      "My current role as the Lead Software Engineer at F(x) Data Labs has provided me the opportunity to develop back-end infrastructures, data pipelines, and ML models for AI-backed products. This has enabled me to experiment with ML techniques while growing my expertise in machine learning and artificial intelligence. In this role I also assisted in improving existing ML frameworks, creating data and model pipelines, as well as integrating AI/analytics into business decision processes. Prior to F(x), I was an Associate Software Engineer for two years where I developed a variety of projects ranging from algorithmic trading platforms for cryptocurrency to Handwritten Ancient Sanskrit Text Recognition Systems. \n",
      "\n",
      "Additionally, I have completed a Bachelorâ€™s degree in Computer Engineering from L.D College of Engineering and boast certifications such as Coursera's Deep Learning Specialization Certificate and Machine Learning Certification by AWS. Furthermore, I have created several research projects on different fields including Knowledge Graphs, Object Detection, Random Forests Applications among others. My research papers have been published and received great feedback from all over the world. \n",
      "\n",
      "The combination of my technical skills, education background and years of experience makes me an excellent choice for this position at Turing. With my experience creating data and model pipelines while working on customer-first environments, I am confident that I can be a valuable addition to your team.\n",
      "\n",
      "I appreciate you taking the time out of your busy schedule to consider my application and look forward to discussing how can I contribute towards your successful project further.  \n",
      "\n",
      "Sincerely, \n",
      "Kadam Parikh\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "# gpt_prompt = \"I have to create a cover letter for me so can you wait for my secound request\"\n",
    "secound_prompt = profile_details + \\\n",
    "    \" this is a profile details. wait for my next request\"\n",
    "third_prompt = job_details + \\\n",
    "    \" this is a job details. wait for my next request\"\n",
    "forth_prompt = \"Can You create a cover letter for maction above profile details and job det\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=gpt_prompt,\n",
    "    temperature=0.99,\n",
    "    max_tokens=2048,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.3,\n",
    "    presence_penalty=0.9,\n",
    "    stop=[\"Job details:\", \"Profile details:\"]\n",
    ")\n",
    "print(\"----------------cover letter----------------------\")\n",
    "result = response['choices'][0]['text']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an indented string.{:>10}\n"
     ]
    }
   ],
   "source": [
    "# indentation = \" \"\n",
    "# string = f\"Write a job cover letter for provided profile details if job application is done for the above mention job details{indentation: > 10}\"\n",
    "\n",
    "indentation = \"    \"\n",
    "indented_string = \"This is an indented string.{:>10}\"\n",
    "print(indented_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'experiences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d36e9a2491ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtodays_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"I have total\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'experiences'"
     ]
    }
   ],
   "source": [
    "data[\"experiences\"]\n",
    "todays_date = date.today()\n",
    "experiences=\"I have total\"\n",
    "for j in range(len(data[\"experiences\"])):\n",
    "    # print(j)\n",
    "    if j==0:\n",
    "        \n",
    "        start_date = str(data[\"experiences\"][j]['starts_at']['year'])+\"-\" + str(data[\"experiences\"]\n",
    "                                                                                [j]['starts_at']['month']) + \"-\" + str(data[\"experiences\"][j]['starts_at']['day'])\n",
    "        end_date = str(todays_date.year) + \"-\" + str(todays_date.month)+\"-\"+str(todays_date.day)\n",
    "        start_date_object = datetime.strptime(str(start_date), \"%Y-%m-%d\")\n",
    "        end_date_object = datetime.strptime(str(end_date), \"%Y-%m-%d\")\n",
    "        total_days = (end_date_object - start_date_object).days\n",
    "\n",
    "        data[\"experiences\"][0]['ends_at'] = todays_date.year\n",
    "        # total_experiences = total_days/365\n",
    "\n",
    "        total_experiences = int(data[\"experiences\"][0]['ends_at']) - int(\n",
    "            data[\"experiences\"][len(data[\"experiences\"])-1]['ends_at']['year'])\n",
    "        experiences += \" \" + str(round(total_experiences,1)) + \" Years of experiences.\"\n",
    "\n",
    "\n",
    "        if total_days > 363:\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_year = total_days/363\n",
    "            each_experiences += \"\" + str(round(each_year, 1)) + \" years of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \".\"\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "        else:\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_month = int(total_days/12)\n",
    "            each_experiences += \"\" + str(each_month) + \" months of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \".\"\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "\n",
    "\n",
    "        # print(experiences)\n",
    "\n",
    "    else:\n",
    "        # print(j)\n",
    "        start_date = str(data[\"experiences\"][j]['starts_at']['year'])+\"-\"+ str(data[\"experiences\"][j]['starts_at']['month']) + \"-\"+ str(data[\"experiences\"][j]['starts_at']['day'])\n",
    "        end_date = str(data[\"experiences\"][j]['ends_at']['year']) + \"-\"+str(data[\"experiences\"][j]['ends_at']['month']) + \"-\"+ str(data[\"experiences\"][j]['ends_at']['day'])\n",
    "        start_date_object = datetime.strptime(str(start_date), \"%Y-%m-%d\")\n",
    "        end_date_object = datetime.strptime(str(end_date), \"%Y-%m-%d\")\n",
    "        total_days = (end_date_object - start_date_object).days\n",
    "        # print(total_days)\n",
    "        if total_days > 363:\n",
    "            # print(total_days)\n",
    "            each_experiences=\"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_year = total_days/360\n",
    "            each_experiences += \"\" + str(round(each_year, 1)) + \" years of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + str(\n",
    "                    data[\"experiences\"][j]['title']) + \", and \" + data[\"experiences\"][j]['description']\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "    \n",
    "        else :\n",
    "            # print(\"totaldays==\",total_days)\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(\"total_days/12==\", total_days/12)\n",
    "            each_month = int(total_days/30)\n",
    "            # print(each_month)\n",
    "            each_experiences += \"\" + str(each_month) + \" months of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \", and \" + \\\n",
    "                data[\"experiences\"][j]['description']\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "    print(experiences)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>\n",
      "\n",
      "\n",
      "Hi Vivek, nice to meet you!\n",
      "\n",
      ">>\n",
      " \n",
      "\n",
      "That's great! It sounds like you have the skills to develop a variety of applications and programs.\n",
      "\n",
      ">>\n",
      " in programming\n",
      "\n",
      "That's wonderful! It sounds like you have a lot of valuable experience that could be beneficial for many projects.\n",
      "\n",
      ">>\n",
      " ?\n",
      "\n",
      "Yes, I can create a cover letter for you to apply with Google.  Please provide me with more details about yourself and the position that you are interested in, so I can tailor the letter to best demonstrate your qualifications.\n",
      "\n",
      ">>\n",
      " field\n",
      "\n",
      "That's great to hear! It sounds like Machine Learning is an area that you find interesting. Please let me know what it is about Machine Learning that you find interesting and I can provide more information on the topic if needed.\n",
      "\n",
      ">>\n",
      "\n",
      "\n",
      "That is great! It sounds like you had a high GPA which is an excellent foundation for your work in the Machine Learning field. Have you had any experience with the technology yet? If not, I can provide some resources to help you get started.\n",
      "\n",
      ">>\n",
      " ?\n",
      "\n",
      "Yes, of course! Please provide me with any information you have about the position you are applying for and your work experience. I will then use this information to create a cover letter that best demonstrates your skills and qualifications.\n",
      "\n",
      ">>\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5732 tokens (3684 in your prompt; 2048 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-189cfba1373b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Sends the prompt and context to the OpenAI API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"context:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"prompt:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             return (\n\u001b[0;32m--> 599\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    600\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 ),\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5732 tokens (3684 in your prompt; 2048 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "#test \n",
    "\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# Setting the API key to use the OpenAI API\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Setting up the logging feature by creating a file with the topic name\n",
    "topic = \"demo\"\n",
    "history_log = 'history/' + re.sub('[^0-9a-zA-Z]+', '', topic) + '.log'\n",
    "file = open(history_log, \"a\")\n",
    "\n",
    "# Initializing the prompt and context variables\n",
    "prompt = \"\"\n",
    "context = \"\"\n",
    "\n",
    "while True:\n",
    "    # Prints '>>' to indicate user input is needed\n",
    "    print(\">>\")\n",
    "    # User input for the prompt\n",
    "    prompt = input()\n",
    "    # If the user inputs 'exit', the loop breaks\n",
    "    if prompt == 'exit':\n",
    "        break\n",
    "    # Writes the user's input to the log file\n",
    "    file.write(prompt)\n",
    "    # Sends the prompt and context to the OpenAI API\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"context:\" + context + \"\\n\\n\" + \"prompt:\" + prompt,\n",
    "        temperature=0.99,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.3,\n",
    "        presence_penalty=0.9\n",
    "    )\n",
    "    # Writes the API's response to the log file\n",
    "    file.write(response[\"choices\"][0][\"text\"] + \"\\n\")\n",
    "    # Prints the API's response\n",
    "    print(response[\"choices\"][0][\"text\"] + \"\\n\")\n",
    "    # Adds the prompt and response to the context variable\n",
    "    context += \"\\n\".join([context, prompt, response[\"choices\"][0][\"text\"]])\n",
    "\n",
    "# Closes the log file\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_filepath = \"Json/job_detail/Turing_ML.json\"\n",
    "with open(job_filepath, 'r') as json_file:\n",
    "    job_data = json.load(json_file)\n",
    "\n",
    "linkedindata = \"random.json\"\n",
    "filepath = \"Json/New data/\"+linkedindata\n",
    "with open(filepath, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "# for skills\n",
    "skills = \"\"\n",
    "for i in range(len(data[\"data\"][\"skills\"])):\n",
    "    skills_data = data[\"data\"][\"skills\"][i]\n",
    "    if i == 0:\n",
    "        skills += \"    \" + skills_data\n",
    "    else:\n",
    "        skills += \", \" + skills_data\n",
    "\n",
    "# for languages\n",
    "languages = \"\"\n",
    "for i in range(len(data[\"data\"][\"languages\"])):\n",
    "    languages_data = data[\"data\"][\"languages\"][i]\n",
    "    if i == 0:\n",
    "        languages += \"    \" + languages_data\n",
    "    else:\n",
    "        languages += \", \" + languages_data\n",
    "\n",
    "# for user_experiences\n",
    "user_experiences = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "    location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "    user_experiences_data = \"    starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Company: \"+str(company) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    description: \"+str(description) +\\\n",
    "        \",\\n\"\"    location: \"+str(location)+\".\\n\"\n",
    "\n",
    "    # print(user_experiences)\n",
    "    user_experiences += \"\\n\"+user_experiences_data\n",
    "\n",
    "# for usereducation\n",
    "usereducation = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usereducation\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['ends_at']\n",
    "    field_of_study = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['field_of_study']\n",
    "    degree_name = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['degree_name']\n",
    "    school = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['school']\n",
    "\n",
    "    usereducation_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Field of study: \"+str(field_of_study) +\\\n",
    "        \",\\n\"\"    Degree name: \"+str(degree_name) +\\\n",
    "        \",\\n\"\"    School: \"+str(school) + \".\\n\"\n",
    "\n",
    "    # print(usereducation)\n",
    "    usereducation += \"\\n\"+usereducation_data\n",
    "\n",
    "# for useraccomplishmentorganisations\n",
    "useraccomplishmentorganisations = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"])):\n",
    "    org_name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['org_name']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['description']\n",
    "\n",
    "    useraccomplishmentorganisations_data = \"    Organisation name: \"+str(org_name) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentorganisations)\n",
    "    useraccomplishmentorganisations += \"\\n\"+useraccomplishmentorganisations_data\n",
    "\n",
    "\n",
    "# for useraccomplishmentprojects\n",
    "useraccomplishmentprojects = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['description']\n",
    "\n",
    "    useraccomplishmentprojects_data = \"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    useraccomplishmentprojects += \"\\n\"+useraccomplishmentprojects_data\n",
    "\n",
    "# for uservolunteerwork\n",
    "uservolunteerwork = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['ends_at']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['description']\n",
    "    cause = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['cause']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['company']\n",
    "\n",
    "    uservolunteerwork_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"    Title: \"+str(title) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) +\\\n",
    "        \",\\n\"\"    Cause: \"+str(cause) +\\\n",
    "        \",\\n\"\"    Company: \"+str(company) + \".\\n\"\n",
    "\n",
    "    # print(uservolunteerwork)\n",
    "    uservolunteerwork += \"\\n\"+uservolunteerwork_data\n",
    "\n",
    "    # print(uservolunteerwork)\n",
    "    uservolunteerwork += \"\\n\"+uservolunteerwork_data\n",
    "\n",
    "# for usercertifications\n",
    "usercertifications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usercertifications\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['starts_at']\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['name']\n",
    "    authority = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['authority']\n",
    "\n",
    "    usercertifications_data = \"    Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"    Name: \"+str(name) +\\\n",
    "        \",\\n\"\"    Authority: \"+str(authority) + \".\\n\"\n",
    "\n",
    "    # print(usercertifications)\n",
    "    usercertifications += \"\\n\"+usercertifications_data\n",
    "\n",
    "# for useraccomplishmentpublications\n",
    "useraccomplishmentpublications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"])):\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['name']\n",
    "    publisher = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['publisher']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['description']\n",
    "\n",
    "    useraccomplishmentpublications_data = \"    Name: \"+str(name) +\\\n",
    "        \",\\n\"\"    Publisher: \"+str(publisher) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentpublications)\n",
    "    useraccomplishmentpublications += \"\\n\"+useraccomplishmentpublications_data\n",
    "\n",
    "# for useraccomplishmenthonorsawards\n",
    "useraccomplishmenthonorsawards = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['title']\n",
    "    issuer = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['issuer']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['description']\n",
    "\n",
    "    useraccomplishmenthonorsawards_data = \"    title: \"+str(title) +\\\n",
    "        \",\\n\"\"    issuer: \"+str(issuer) +\\\n",
    "        \",\\n\"\"    Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmenthonorsawards)\n",
    "    useraccomplishmenthonorsawards += \"\\n\"+useraccomplishmenthonorsawards_data\n",
    "\n",
    "\n",
    "First_name = str(data[\"data\"][\"first_name\"])\n",
    "last_name = data[\"data\"][\"last_name\"]\n",
    "Occupation = data[\"data\"][\"occupation\"]\n",
    "Email = data[\"data\"][\"email\"]\n",
    "Summary = data[\"data\"][\"summary\"]\n",
    "Country_full_name = data[\"data\"][\"country_full_name\"]\n",
    "City = data[\"data\"][\"city\"]\n",
    "state = data[\"data\"][\"state\"]\n",
    "# Languages = data[\"data\"][\"languages\"]\n",
    "Languages = languages\n",
    "# skills = data[\"data\"][\"skills\"]\n",
    "skills = skills\n",
    "\n",
    "# User_experiences = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"]\n",
    "User_experiences = user_experiences\n",
    "\n",
    "# User_education = data[\"data\"][\"user_carrier_data\"][\"usereducation\"]\n",
    "User_education = usereducation\n",
    "\n",
    "# User_accomplishment_organisations = data[\"data\"][\n",
    "# \"user_carrier_data\"][\"useraccomplishmentorganisations\"]\n",
    "User_accomplishment_organisations = useraccomplishmentorganisations\n",
    "\n",
    "# User_accomplishment_projects = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]\n",
    "User_accomplishment_projects = useraccomplishmentprojects\n",
    "\n",
    "# User_volunteer_work = User_certifications = data[\n",
    "#     \"data\"][\"user_carrier_data\"][\"uservolunteerwork\"]\n",
    "User_volunteer_work = uservolunteerwork\n",
    "\n",
    "# User_certifications = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"]\n",
    "User_certifications = usercertifications\n",
    "\n",
    "# User_accomplishment_publications = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmentpublications\"]\n",
    "User_accomplishment_publications = useraccomplishmentpublications\n",
    "\n",
    "# User_accomplishment_honors_awards = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmenthonorsawards\"]\n",
    "User_accomplishment_honors_awards = useraccomplishmenthonorsawards\n",
    "\n",
    "\n",
    "job_description = job_data[\"job_description\"]\n",
    "\n",
    "title = job_data[\"title\"]\n",
    "location = str(job_data[\"location\"][\"city\"]) + \",\" + \\\n",
    "    str(job_data[\"location\"][\"region\"])+\",\" + \\\n",
    "    str(job_data[\"location\"][\"country\"])\n",
    "company = job_data[\"company\"][\"name\"]\n",
    "industry = job_data[\"industry\"][0]\n",
    "employment_type = job_data[\"employment_type\"]\n",
    "job_functions = job_data[\"job_functions\"][0]\n",
    "\n",
    "profile_details = \"Profile details:\\n\" \\\n",
    "    \"Name: \"+str(First_name) + \" \"+str(last_name) + \"\\n\"\\\n",
    "    \"Occupation: \"+str(Occupation) + \"\\n\"\\\n",
    "    \"Email: \"+str(Email) + \"\\n\"\\\n",
    "    \"Summary: \"+str(Summary) + \"\\n\"\\\n",
    "    \"Country: \"+str(Country_full_name) + \"\\n\"\\\n",
    "    \"City: \"+str(City) + \"\\n\"\\\n",
    "    \"state: \"+str(state) + \"\\n\"\\\n",
    "    \"Languages: \"+str(Languages) + \"\\n\"\\\n",
    "    \"skills: \"+str(skills) + \"\\n\"\\\n",
    "    \"experiences: \"+str(User_experiences) + \"\\n\"\\\n",
    "    \"education: \"+str(User_education) + \"\\n\"\\\n",
    "    \"accomplishment_organisations: \"+str(User_accomplishment_organisations) + \"\\n\"\\\n",
    "    \"projects: \"+str(User_accomplishment_projects) + \"\\n\"\\\n",
    "    \"Volunteer work: \"+str(User_volunteer_work) + \"\\n\"\\\n",
    "    \"certifications: \"+str(User_certifications) + \"\\n\"\\\n",
    "    \"publications: \"+str(User_accomplishment_publications) + \"\\n\"\\\n",
    "    \"honors_awards: \"+str(User_accomplishment_honors_awards) + \"\\n\"\n",
    "\n",
    "\n",
    "job_details = \"Job details:\\n \"\\\n",
    "    \"    Title: \"+str(title) + \"\\n\"\\\n",
    "    \"    Compnay name: \"+str(company) + \"\\n\"\\\n",
    "    \"    Location: \"+str(location) + \"\\n\"\\\n",
    "    \"    Industry: \"+str(industry) + \"\\n\"\\\n",
    "    \"    Job description: \"+str(job_description) + \"\\n\"\\\n",
    "    \"    Employment type: \"+str(employment_type) + \"\\n\"\\\n",
    "    \"    Job functions: \"+str(job_functions) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      "     Title: Remote Machine Learning Engineer Jobs\n",
      "    Compnay name: Turing\n",
      "    Location: None,None,India\n",
      "    Industry: Software Development\n",
      "    Job description: An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "**Job Responsibilities:**\n",
      "  \n",
      "\n",
      "  * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "  * Experiment with ML techniques to create and test new program features\n",
      "  * Assist in extending and improving existing ML frameworks and libraries\n",
      "  * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "  * Integrate ML models to end-users and run experiments\n",
      "  * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "**Job Requirements:**\n",
      "  \n",
      "\n",
      "  * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "  * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "  * Must have hands-on experience in Adaptive Learning Systems \n",
      "  * Should be well versed in MEAN and/or MERN stacks\n",
      "  * Expertise in Machine Learning and Artificial Intelligence \n",
      "  * Experience in data science projects and psychometrics is required\n",
      "  * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "    Employment type: Full-time\n",
      "    Job functions: Engineering and Information Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------cover letter----------------------\n",
      "\n",
      "\n",
      "Dear Turing Hiring Team,\n",
      "\n",
      "I am writing to apply for the position of Remote Machine Learning Engineer at your company, Turing. \n",
      "I believe my profile and experience make me well-suited for this opportunity. As an experienced DLP Architect at i4DM specializing in Machine Learning and Artificial Intelligence, I bring the following qualifications:\n",
      "\n",
      "* Over 3+ years of expertise as a Machine Learning Engineer with proficiency in MEAN and MERN stacks.\n",
      "* Extensive experience in Adaptive Learning Systems and psychometrics.\n",
      "* Proven ability to build back-end infrastructure, data pipelines, and ML models for AI-backed products.\n",
      "* History of integrating ML models to end-users and running experiments.\n",
      "* Skills in developing data and model pipelines, carrying out statistical analysis, test results interpretation, tuning, and scaling.\n",
      "* Excellent communication skills with knowledge of English language. \n",
      "* Immense familiarity working with customer networks regarding sensitive data protection.  capability to write scripts for automation as well as developing C/C++ libraries for serializing data are also keystrengths that add value to my candidacy. \n",
      "\n",
      " My most recent responsibilities at i4DM included developing policies for protecting sensitive data and managing diverse tasks that involved providing technical support with troubleshooting products from component level upwards. In the past five years - since 2012 - I have worked as an Embedded Systems Developer at New York Air Brake followed by another role as Sustaining Engineer while prior to that being employed as an Embedded Systems Developer at Fuel7 - all of which complemented my professional journey as a Cybersecurity Engineer between June 2018 to May 2022 at GM Financial; a venture where I was successfully able to reduce long process time from days/hours to minutes with scripts written in Perl and Python while also assisting associates on customizing ransomware detection policies via tuning existing patterns. \n",
      "\n",
      "Currently enrolled in Tableau 2022: Hands-On Tableau Training For Data Science! certification course and certified in AWS Cloud Practitioner postgraduate program; it gives me immense pleasure that I am also eligible for further validations such as Certified Information Security Manager (CISM), Certified Ethical Hacker (CEH), CVEÂ® Qualified Professional, Cyber Security Technician Certificate Examination (CSET) among many others which reflects my commitment towards ongoing professional development resulting in comprehensive technological prowess over the years coupled by clear customer orientation due to simultaneous involvement within Domains like Aerospace & Defense industries, Environmental Monitoring systems etcetera. \n",
      "\n",
      " With all the richness gleaned from multi-dimensional roles held over two decades plus prior acumen devised through Bachelor's degree in Electronics & Electricals Engineering supporting hands-on capabilities imbedded through research projects conducted on various aspects such as embedded system design testing etcetera â€“ rest assured that I possess significant expertise related to this job requirement combining ethical behavior amongst teammates within Internal/External work environments while simultaneously fetching customer loyalty & satisfaction effectively within target timeframe owing to innovative ideas supplemented by agile methodologies gaining momentum towards realization of organizationâ€™s strategic plans/objectives positioning myself optimally amongst peers standing out arch above competition offering business acumen decision making capacities rooted deeply within science & technology powered deliverables conquering roadblocks without fail reaching Definitive goal oriented success winning applauds alike catapulting golden moments across domain specific initiatives undertaken during tenure period pursued until today leading towards inspirational mutating shift toward destination beyond skyâ€™s limit yet exponential excellence within innovation !! \n",
      "\n",
      " If given the chance, I can be all these great qualities together and much more you need in the role of Remote Machine Learning Engineer at Turing. Thank you very much for taking out your valuable time considering my application despite busy schedule Best Regards Jaime Vinay~\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "# gpt_prompt = \"I have to create a cover letter for me so can you wait for my secound request\"\n",
    "# secound_prompt = profile_details + \\\n",
    "#     \" this is a profile details. wait for my next request\"\n",
    "# third_prompt = job_details + \\\n",
    "#     \" this is a job details. wait for my next request\"\n",
    "# forth_prompt = \"Can You classic create a cover letter for mention above profile details and job details\"\n",
    "# ------final corpus starts-------\n",
    "gpt_prompt = job_details + \"\\n \"+profile_details + \\\n",
    "    \"\\nWrite a job professional cover letter for provided profile details if job application is done for the above mention job details\"\n",
    "\n",
    "# ------final corpus ends-----\n",
    "# print(gpt_prompt)\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=gpt_prompt,\n",
    "    temperature=0.99,\n",
    "    max_tokens=2048,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.3,\n",
    "    presence_penalty=0.9,\n",
    "    stop=[\"Job details:\", \"Profile details:\"]\n",
    ")\n",
    "print(\"----------------cover letter----------------------\")\n",
    "result = response['choices'][0]['text']\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
