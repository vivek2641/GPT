{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedindata = \"hemen.json\"\n",
    "filepath = \"Json/New data/\"+linkedindata\n",
    "with open(filepath, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For get all the data from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    agile methodologies, ajax, algorithm design, artificial intelligence, artificial neural networks, business strategy, c, c++, core java, css, css3, data science, data structures, design patterns, event management, facebook api, facebook open graph protocols, gamification, html, html 5, html5, j2se, java, javascript, jquery, json, linux, machine learning, magento, marketing strategy, mysql, natural language processing, node.js, parallax, php, poetry, product design, programming, python, risk management, semantic web, seo, software development, start ups, venture development, web applications, web development, web services, zend framework\n"
     ]
    }
   ],
   "source": [
    "skills=\"\"\n",
    "for i in range(len(data[\"data\"][\"skills\"])):\n",
    "    skills_data=data[\"data\"][\"skills\"][i]\n",
    "    if i == 0:\n",
    "        skills += \"\\n\" + skills_data\n",
    "    else:\n",
    "        skills += \", \" + skills_data\n",
    "skills = textwrap.indent(skills, \"    \")\n",
    "print(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    English, Gujarati, Hindi\n"
     ]
    }
   ],
   "source": [
    "languages = \"\"\n",
    "for i in range(len(data[\"data\"][\"languages\"])):\n",
    "    languages_data = data[\"data\"][\"languages\"][i]\n",
    "    if i == 0:\n",
    "        languages += \"\\n\" + languages_data\n",
    "    else:\n",
    "        languages += \", \" + languages_data\n",
    "\n",
    "languages = textwrap.indent(languages, \"    \")\n",
    "print(languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starts at: 2018-11-01T00:00:00Z,\n",
      "Ends at: None,\n",
      "Company: Medlex.ai,\n",
      "Title: Machine Learning Developer,\n",
      "description: None,\n",
      "location: None.\n",
      "\n",
      "starts at: 2015-03-01T00:00:00Z,\n",
      "Ends at: 2015-07-31T00:00:00Z,\n",
      "Company: Zidisha,\n",
      "Title: Chief Technology Officer,\n",
      "description: Zidisha is the first online microlending community that directly connects lenders and borrowers — no matter the distance or disparity between them.\n",
      "\n",
      "More than 200,000 people worldwide have started using Zidisha.,\n",
      "location: Ahmedabad Area, India.\n",
      "\n",
      "starts at: 2013-05-01T00:00:00Z,\n",
      "Ends at: 2015-02-28T00:00:00Z,\n",
      "Company: Remarkin.com,\n",
      "Title: Founder / CEO,\n",
      "description: Remarkin.com is a start-up venture aims to make education easy, engaging and creative.,\n",
      "location: Ahmedabad.\n",
      "\n",
      "starts at: 2013-03-01T00:00:00Z,\n",
      "Ends at: 2015-02-28T00:00:00Z,\n",
      "Company: Venture Design Fellow,\n",
      "Title: Venture Studio,\n",
      "description: Venture Studio program follows a design methodology based from research conducted in the field of engineering and product innovation. The program is run by Ahmedabad University in Collaboration with Center for Design Research at Stanford University,\n",
      "location: Ahmedabad Area, India.\n",
      "\n",
      "starts at: 2012-07-01T00:00:00Z,\n",
      "Ends at: 2013-04-30T00:00:00Z,\n",
      "Company: Aspire Institute,\n",
      "Title: Trainer/ faculty,\n",
      "description: Coaching for Advance web development with PHP,\n",
      "location: None.\n",
      "\n",
      "starts at: 2012-07-01T00:00:00Z,\n",
      "Ends at: 2012-10-31T00:00:00Z,\n",
      "Company: Vox Populi Club,\n",
      "Title: Tech-Event Manager,\n",
      "description: VP-club is club in L.D. College of Engineering, Ahmedabad.\n",
      "that organizes events to keep Engineers Beating ..:),\n",
      "location: Ahmedabad Area, India.\n",
      "\n",
      "starts at: 2012-01-01T00:00:00Z,\n",
      "Ends at: 2012-12-31T00:00:00Z,\n",
      "Company: Vox Populi Magazine,\n",
      "Title: Techtonic,\n",
      "description: Working for tech department of Vox-Populi Magazine.,\n",
      "location: None.\n",
      "\n",
      "starts at: 2012-01-01T00:00:00Z,\n",
      "Ends at: 2012-11-30T00:00:00Z,\n",
      "Company: Vox Populi Club,\n",
      "Title: Manager OF Technical Events,\n",
      "description: I work as a Technical Event manger at Vox Populi Club\n",
      "In LD College of Engineering Ahmedabad,\n",
      "location: Ahmedabad.\n",
      "\n",
      "starts at: 2011-08-01T00:00:00Z,\n",
      "Ends at: 2012-04-30T00:00:00Z,\n",
      "Company: Topupchat.com,\n",
      "Title: CEO/founder,\n",
      "description: As a CEO I invent all new feature of this website topupchat.com,\n",
      "the entire idea, code and design of this website is designed and invented by me,\n",
      "location: None.\n",
      "\n",
      "starts at: 2018-03-01T00:00:00Z,\n",
      "Ends at: 2019-12-31T00:00:00Z,\n",
      "Company: ArtuData,\n",
      "Title: Chief Data Scientist,\n",
      "description: 80% of your profit is generated by just 2% of your visitors\n",
      "ArtuData empowers your marketing and sales teams to identify leads in real-time, giving each team full focus to convert them into paying customers. Now you can boost your efficiency and ROI while reducing your cost per acquisition.,\n",
      "location: Ahmedabad Area, India.\n",
      "\n",
      "starts at: 2018-01-01T00:00:00Z,\n",
      "Ends at: 2018-12-31T00:00:00Z,\n",
      "Company: Johnson & Johnson,\n",
      "Title: Lead Data Scientist and Machine Learning Expert,\n",
      "description: Worked as a Lead Data Scientist and Machine Learning Expert at Johnson & Johnson - Data Science.\n",
      "Created data pipelines, which used millions of data points, for the identification of the best strategies to increase the effectiveness of professional educational events.,\n",
      "location: None.\n",
      "\n",
      "starts at: 2018-01-01T00:00:00Z,\n",
      "Ends at: 2018-12-31T00:00:00Z,\n",
      "Company: Loom Network,\n",
      "Title: Lead Go Developer,\n",
      "description: Built a Karma system for a decentralized crypto platform and implemented a Sparse Merkle Tree.,\n",
      "location: None.\n",
      "\n",
      "starts at: 2018-01-01T00:00:00Z,\n",
      "Ends at: 2018-12-31T00:00:00Z,\n",
      "Company: Paravision,\n",
      "Title: TensorFlow Expert,\n",
      "description: Invented the fastest algorithm to identify the correct face using machine learning with a 99.81% accuracy.,\n",
      "location: None.\n",
      "\n",
      "starts at: 2015-08-01T00:00:00Z,\n",
      "Ends at: None,\n",
      "Company: F(x) Data Labs PVT LTD,\n",
      "Title: Founder / Chief Scientist,\n",
      "description: At F(x) Data Labs, we are working on our algorithm called h+tree which increases the speed limit of the databases that serves more number of users at a time.\n",
      "\n",
      " h+ tree is capable to deliver 300% speed compared to the existing B+Tree. Hence your servers will become exceptionally fast and your server cost also goes down eventually.\n",
      "\n",
      "The end goal for setting up our cloud infrastructure is that we want to inject our h+Tree algorithm into our cloud servers and we look forward to delivering the fastest cloud servers to the entire software industry!,\n",
      "location: Ahmedabad Area, India.\n",
      "\n",
      "starts at: 2012-05-01T00:00:00Z,\n",
      "Ends at: 2012-07-31T00:00:00Z,\n",
      "Company: Amitech,\n",
      "Title: Web Developer,\n",
      "description: Worked as Facebook Application Developer and Firefox Extension Developer at Amitech.\n",
      "Amitech is a software solution company from Ahmedabad.,\n",
      "location: Ahmedabad Area, India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_experiences = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "    location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "    user_experiences_data = \"starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"Company: \"+str(company) +\\\n",
    "        \",\\n\"\"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"description: \"+str(description) +\\\n",
    "        \",\\n\"\"location: \"+str(location)+\".\\n\"\n",
    "\n",
    "        # print(user_experiences)\n",
    "    user_experiences +=  \"\\n\"+user_experiences_data\n",
    "    \n",
    "user_experiences = textwrap.indent(user_experiences, \"    \")\n",
    "print(user_experiences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_experiences = \"\"\n",
    "\n",
    "# for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    \n",
    "#     print(j)\n",
    "#     # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j])\n",
    "#     # print(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at'])\n",
    "\n",
    "#     if j<4:\n",
    "#         starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "#         ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "#         company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "#         title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "#         description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "#         location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "#         user_experiences_data = \"    starts at: \"+str(starts_at) +\\\n",
    "#             \",\\n\"\"    Ends at: \"+str(ends_at) +\\\n",
    "#             \",\\n\"\"    Company: \"+str(company) +\\\n",
    "#             \",\\n\"\"    Title: \"+str(title) +\\\n",
    "#             \",\\n\"\"    description: \"+str(description) +\\\n",
    "#             \",\\n\"\"    location: \"+str(location)+\".\\n\"\n",
    "\n",
    "#         # print(user_experiences)\n",
    "#         user_experiences += \"\\n\"+user_experiences_data\n",
    "# print(user_experiences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Starts at: 2013-01-01T00:00:00Z,\n",
      "    Ends at: 2015-12-31T00:00:00Z,\n",
      "    Field of study: Entrepreneurship and Design Thinking,\n",
      "    Degree name: Fellowship,\n",
      "    School: VentureStudio Partnered with Stanford University, California.\n",
      "\n",
      "    Starts at: 2010-01-01T00:00:00Z,\n",
      "    Ends at: 2014-12-31T00:00:00Z,\n",
      "    Field of study: IT,\n",
      "    Degree name: BE,\n",
      "    School: L.D College of Engineering - Ahmedabad.\n",
      "\n",
      "    Starts at: 2003-01-01T00:00:00Z,\n",
      "    Ends at: 2010-12-31T00:00:00Z,\n",
      "    Field of study: Science,\n",
      "    Degree name: 12th,\n",
      "    School: V. D. High School, Bhuj-Kutch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usereducation = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usereducation\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['ends_at']\n",
    "    field_of_study = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['field_of_study']\n",
    "    degree_name = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['degree_name']\n",
    "    school = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['school']\n",
    "    \n",
    "    usereducation_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\nEnds at: \"+str(ends_at) +\\\n",
    "        \",\\nField of study: \"+str(field_of_study) +\\\n",
    "        \",\\nDegree name: \"+str(degree_name) +\\\n",
    "        \",\\nSchool: \"+str(school) +\".\\n\"\n",
    "\n",
    "    # print(usereducation)\n",
    "    usereducation += \"\\n\"+usereducation_data\n",
    "\n",
    "usereducation = textwrap.indent(usereducation, \"    \")\n",
    "\n",
    "print(usereducation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentorganisations = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"])):\n",
    "    org_name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['org_name']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentorganisations_data = \"Organisation name: \"+str(org_name) +\\\n",
    "        \",\\nTitle: \"+str(title) +\\\n",
    "        \",\\nDescription: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentorganisations)\n",
    "    useraccomplishmentorganisations += \"\\n\"+useraccomplishmentorganisations_data\n",
    "\n",
    "useraccomplishmentorganisations = textwrap.indent(\n",
    "    useraccomplishmentorganisations, \"    \")\n",
    "print(useraccomplishmentorganisations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "\n",
      "    Title: Topupchat.com(Free Recharge),\n",
      "    Description: Chat with your fiends and get free Mobile Recharge.\n",
      "\n",
      "    Title: Net Meeting,\n",
      "    Description: A portal for easy virtual meeting..\n",
      "\n",
      "    Title: ICATES2013,\n",
      "    Description: A responsive website for an International Conference on Advances in Tribology and Engineering Systems.\n",
      "\n",
      "    Title: MN Framework,\n",
      "    Description: An extremely robust and easy to use framework of highly distributed development of Advance PHP web projects.\n",
      "    Helpful for beginners - intermediates and experts.\n",
      "\n",
      "    Title: LGD Library,\n",
      "    Description: Layered image processing library for PHP.\n",
      "\n",
      "    Title: Me Famous,\n",
      "    Description: an app to update fb status in a stylish way.\n",
      "\n",
      "    Title: PicInChat.com,\n",
      "    Description: upload & Send pic to facebook friends in chat as big smiles.\n",
      "\n",
      "    Title: Just Debate,\n",
      "    Description: Just Debate - war of the words\n",
      "    An Event of Technical debate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentprojects = \"\"\n",
    "print(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]))\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentprojects_data = \"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    useraccomplishmentprojects += \"\\n\"+useraccomplishmentprojects_data\n",
    "    \n",
    "\n",
    "useraccomplishmentprojects = textwrap.indent(\n",
    "    useraccomplishmentprojects, \"    \")\n",
    "\n",
    "print(useraccomplishmentprojects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uservolunteerwork = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['ends_at']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['description']\n",
    "    cause = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['cause']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['company']\n",
    "\n",
    "    uservolunteerwork_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) +\\\n",
    "        \",\\n\"\"Cause: \"+str(cause) +\\\n",
    "        \",\\n\"\"Company: \"+str(company) + \".\\n\"\n",
    "\n",
    "    # print(uservolunteerwork)\n",
    "    uservolunteerwork += \"\\n\"+uservolunteerwork_data\n",
    "\n",
    "uservolunteerwork = textwrap.indent(\n",
    "    uservolunteerwork, \"    \")\n",
    "print(uservolunteerwork)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usercertifications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usercertifications\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['starts_at']\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['name']\n",
    "    authority = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['authority']\n",
    "   \n",
    "\n",
    "    usercertifications_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Name: \"+str(name) +\\\n",
    "        \",\\n\"\"Authority: \"+str(authority) +\".\\n\"\n",
    "\n",
    "    # print(usercertifications)\n",
    "    usercertifications += \"\\n\"+usercertifications_data\n",
    "usercertifications = textwrap.indent(\n",
    "    usercertifications, \"    \")\n",
    "print(usercertifications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Name: Fx Optimiser upto 80% faster Artificial Neural Network Training,\n",
      "    Publisher: OpenReview,\n",
      "    Description: Fx Optimiser is successor to Adam Optimiser.\n",
      "    It is observed to throuput upto 80% faster Artificial Neural Network Training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmentpublications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"])):\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['name']\n",
    "    publisher = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['publisher']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['description']\n",
    "    \n",
    "    useraccomplishmentpublications_data = \"Name: \"+str(name) +\\\n",
    "        \",\\n\"\"Publisher: \"+str(publisher) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentpublications)\n",
    "    useraccomplishmentpublications += \"\\n\"+useraccomplishmentpublications_data\n",
    "useraccomplishmentpublications = textwrap.indent(\n",
    "    useraccomplishmentpublications, \"    \")\n",
    "print(useraccomplishmentpublications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Title: Leadership and Excellence Award,\n",
      "    Issuer: Gujarat Technological University, Ahmedabad, Gujarat, India,\n",
      "    Description: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useraccomplishmenthonorsawards = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['title']\n",
    "    issuer = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['issuer']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['description']\n",
    "\n",
    "    useraccomplishmenthonorsawards_data = \"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Issuer: \"+str(issuer) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmenthonorsawards)\n",
    "    useraccomplishmenthonorsawards += \"\\n\"+useraccomplishmenthonorsawards_data\n",
    "useraccomplishmenthonorsawards = textwrap.indent(\n",
    "    useraccomplishmenthonorsawards, \"    \")\n",
    "print(useraccomplishmenthonorsawards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_name = str(data[\"data\"][\"first_name\"])\n",
    "last_name = data[\"data\"][\"last_name\"]\n",
    "Occupation = data[\"data\"][\"occupation\"]\n",
    "Email = data[\"data\"][\"email\"]\n",
    "Summary = data[\"data\"][\"summary\"]\n",
    "Country_full_name = data[\"data\"][\"country_full_name\"]\n",
    "City = data[\"data\"][\"city\"]\n",
    "state = data[\"data\"][\"state\"]\n",
    "# Languages = data[\"data\"][\"languages\"]\n",
    "Languages = languages\n",
    "# skills = data[\"data\"][\"skills\"]\n",
    "skills = skills\n",
    "\n",
    "# User_experiences = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"]\n",
    "User_experiences = user_experiences\n",
    "\n",
    "# User_education = data[\"data\"][\"user_carrier_data\"][\"usereducation\"]\n",
    "User_education = usereducation\n",
    "\n",
    "# User_accomplishment_organisations = data[\"data\"][\n",
    "    # \"user_carrier_data\"][\"useraccomplishmentorganisations\"]\n",
    "User_accomplishment_organisations = useraccomplishmentorganisations\n",
    "\n",
    "# User_accomplishment_projects = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]\n",
    "User_accomplishment_projects = useraccomplishmentprojects\n",
    "\n",
    "# User_volunteer_work = User_certifications = data[\n",
    "#     \"data\"][\"user_carrier_data\"][\"uservolunteerwork\"]\n",
    "User_volunteer_work = uservolunteerwork\n",
    "\n",
    "# User_certifications = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"]\n",
    "User_certifications = usercertifications\n",
    "\n",
    "# User_accomplishment_publications = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmentpublications\"]\n",
    "User_accomplishment_publications = useraccomplishmentpublications\n",
    "\n",
    "# User_accomplishment_honors_awards = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmenthonorsawards\"]\n",
    "User_accomplishment_honors_awards = useraccomplishmenthonorsawards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_details = \"Profile details:\\n\" \\\n",
    "    \"Name: \\n     \"+str(First_name) + \" \"+str(last_name) + \"\\n\"\\\n",
    "    \"Occupation: \\n     \"+str(Occupation) + \"\\n\"\\\n",
    "    \"Email: \\n     \"+str(Email) + \"\\n\"\\\n",
    "    \"Summary: \\n     \"+str(Summary) + \"\\n\"\\\n",
    "    \"Country: \\n     \"+str(Country_full_name) + \"\\n\"\\\n",
    "    \"City: \\n     \"+str(City) + \"\\n\"\\\n",
    "    \"State: \\n     \"+str(state) + \"\\n\"\\\n",
    "    \"Languages: \"+str(Languages) + \"\\n\"\\\n",
    "    \"Skills: \"+str(skills) + \"\\n\"\\\n",
    "    \"Experiences: \"+str(User_experiences) + \"\\n\"\\\n",
    "    \"Education: \"+str(User_education) + \"\\n\"\\\n",
    "    \"Accomplishment organisations: \"+str(User_accomplishment_organisations) + \"\\n\"\\\n",
    "    \"Projects: \"+str(User_accomplishment_projects) + \"\\n\"\\\n",
    "    \"Volunteer work: \"+str(User_volunteer_work) + \"\\n\"\\\n",
    "    \"Certifications: \"+str(User_certifications) + \"\\n\"\\\n",
    "    \"Publications: \"+str(User_accomplishment_publications) + \"\\n\"\\\n",
    "    \"Honors_awards: \"+str(User_accomplishment_honors_awards) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile details:\n",
      "Name: \n",
      "     Hemen Ashodia\n",
      "Occupation: \n",
      "     Founder / Chief Scientist at F(x) Data Labs PVT LTD\n",
      "Email: \n",
      "     hemen@htree.plus\n",
      "Summary: \n",
      "     To invent.\n",
      "Country: \n",
      "     India\n",
      "City: \n",
      "     Ahmedabad\n",
      "State: \n",
      "     Gujarat\n",
      "Languages: \n",
      "    English, Gujarati, Hindi\n",
      "Skills: \n",
      "    agile methodologies, ajax, algorithm design, artificial intelligence, artificial neural networks, business strategy, c, c++, core java, css, css3, data science, data structures, design patterns, event management, facebook api, facebook open graph protocols, gamification, html, html 5, html5, j2se, java, javascript, jquery, json, linux, machine learning, magento, marketing strategy, mysql, natural language processing, node.js, parallax, php, poetry, product design, programming, python, risk management, semantic web, seo, software development, start ups, venture development, web applications, web development, web services, zend framework\n",
      "Experiences: \n",
      "    starts at: 2018-11-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: Medlex.ai,\n",
      "    Title: Machine Learning Developer,\n",
      "    description: None,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2015-03-01T00:00:00Z,\n",
      "    Ends at: 2015-07-31T00:00:00Z,\n",
      "    Company: Zidisha,\n",
      "    Title: Chief Technology Officer,\n",
      "    description: Zidisha is the first online microlending community that directly connects lenders and borrowers — no matter the distance or disparity between them.\n",
      "\n",
      "    More than 200,000 people worldwide have started using Zidisha.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2013-05-01T00:00:00Z,\n",
      "    Ends at: 2015-02-28T00:00:00Z,\n",
      "    Company: Remarkin.com,\n",
      "    Title: Founder / CEO,\n",
      "    description: Remarkin.com is a start-up venture aims to make education easy, engaging and creative.,\n",
      "    location: Ahmedabad.\n",
      "\n",
      "    starts at: 2013-03-01T00:00:00Z,\n",
      "    Ends at: 2015-02-28T00:00:00Z,\n",
      "    Company: Venture Design Fellow,\n",
      "    Title: Venture Studio,\n",
      "    description: Venture Studio program follows a design methodology based from research conducted in the field of engineering and product innovation. The program is run by Ahmedabad University in Collaboration with Center for Design Research at Stanford University,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-07-01T00:00:00Z,\n",
      "    Ends at: 2013-04-30T00:00:00Z,\n",
      "    Company: Aspire Institute,\n",
      "    Title: Trainer/ faculty,\n",
      "    description: Coaching for Advance web development with PHP,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2012-07-01T00:00:00Z,\n",
      "    Ends at: 2012-10-31T00:00:00Z,\n",
      "    Company: Vox Populi Club,\n",
      "    Title: Tech-Event Manager,\n",
      "    description: VP-club is club in L.D. College of Engineering, Ahmedabad.\n",
      "    that organizes events to keep Engineers Beating ..:),\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-01-01T00:00:00Z,\n",
      "    Ends at: 2012-12-31T00:00:00Z,\n",
      "    Company: Vox Populi Magazine,\n",
      "    Title: Techtonic,\n",
      "    description: Working for tech department of Vox-Populi Magazine.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2012-01-01T00:00:00Z,\n",
      "    Ends at: 2012-11-30T00:00:00Z,\n",
      "    Company: Vox Populi Club,\n",
      "    Title: Manager OF Technical Events,\n",
      "    description: I work as a Technical Event manger at Vox Populi Club\n",
      "    In LD College of Engineering Ahmedabad,\n",
      "    location: Ahmedabad.\n",
      "\n",
      "    starts at: 2011-08-01T00:00:00Z,\n",
      "    Ends at: 2012-04-30T00:00:00Z,\n",
      "    Company: Topupchat.com,\n",
      "    Title: CEO/founder,\n",
      "    description: As a CEO I invent all new feature of this website topupchat.com,\n",
      "    the entire idea, code and design of this website is designed and invented by me,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-03-01T00:00:00Z,\n",
      "    Ends at: 2019-12-31T00:00:00Z,\n",
      "    Company: ArtuData,\n",
      "    Title: Chief Data Scientist,\n",
      "    description: 80% of your profit is generated by just 2% of your visitors\n",
      "    ArtuData empowers your marketing and sales teams to identify leads in real-time, giving each team full focus to convert them into paying customers. Now you can boost your efficiency and ROI while reducing your cost per acquisition.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Johnson & Johnson,\n",
      "    Title: Lead Data Scientist and Machine Learning Expert,\n",
      "    description: Worked as a Lead Data Scientist and Machine Learning Expert at Johnson & Johnson - Data Science.\n",
      "    Created data pipelines, which used millions of data points, for the identification of the best strategies to increase the effectiveness of professional educational events.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Loom Network,\n",
      "    Title: Lead Go Developer,\n",
      "    description: Built a Karma system for a decentralized crypto platform and implemented a Sparse Merkle Tree.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Paravision,\n",
      "    Title: TensorFlow Expert,\n",
      "    description: Invented the fastest algorithm to identify the correct face using machine learning with a 99.81% accuracy.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2015-08-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: F(x) Data Labs PVT LTD,\n",
      "    Title: Founder / Chief Scientist,\n",
      "    description: At F(x) Data Labs, we are working on our algorithm called h+tree which increases the speed limit of the databases that serves more number of users at a time.\n",
      "\n",
      "     h+ tree is capable to deliver 300% speed compared to the existing B+Tree. Hence your servers will become exceptionally fast and your server cost also goes down eventually.\n",
      "\n",
      "    The end goal for setting up our cloud infrastructure is that we want to inject our h+Tree algorithm into our cloud servers and we look forward to delivering the fastest cloud servers to the entire software industry!,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-05-01T00:00:00Z,\n",
      "    Ends at: 2012-07-31T00:00:00Z,\n",
      "    Company: Amitech,\n",
      "    Title: Web Developer,\n",
      "    description: Worked as Facebook Application Developer and Firefox Extension Developer at Amitech.\n",
      "    Amitech is a software solution company from Ahmedabad.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "Education: \n",
      "    Starts at: 2013-01-01T00:00:00Z,\n",
      "    Ends at: 2015-12-31T00:00:00Z,\n",
      "    Field of study: Entrepreneurship and Design Thinking,\n",
      "    Degree name: Fellowship,\n",
      "    School: VentureStudio Partnered with Stanford University, California.\n",
      "\n",
      "    Starts at: 2010-01-01T00:00:00Z,\n",
      "    Ends at: 2014-12-31T00:00:00Z,\n",
      "    Field of study: IT,\n",
      "    Degree name: BE,\n",
      "    School: L.D College of Engineering - Ahmedabad.\n",
      "\n",
      "    Starts at: 2003-01-01T00:00:00Z,\n",
      "    Ends at: 2010-12-31T00:00:00Z,\n",
      "    Field of study: Science,\n",
      "    Degree name: 12th,\n",
      "    School: V. D. High School, Bhuj-Kutch.\n",
      "\n",
      "Accomplishment organisations: \n",
      "Projects: \n",
      "    Title: Topupchat.com(Free Recharge),\n",
      "    Description: Chat with your fiends and get free Mobile Recharge.\n",
      "\n",
      "    Title: Net Meeting,\n",
      "    Description: A portal for easy virtual meeting..\n",
      "\n",
      "    Title: ICATES2013,\n",
      "    Description: A responsive website for an International Conference on Advances in Tribology and Engineering Systems.\n",
      "\n",
      "    Title: MN Framework,\n",
      "    Description: An extremely robust and easy to use framework of highly distributed development of Advance PHP web projects.\n",
      "    Helpful for beginners - intermediates and experts.\n",
      "\n",
      "    Title: LGD Library,\n",
      "    Description: Layered image processing library for PHP.\n",
      "\n",
      "    Title: Me Famous,\n",
      "    Description: an app to update fb status in a stylish way.\n",
      "\n",
      "    Title: PicInChat.com,\n",
      "    Description: upload & Send pic to facebook friends in chat as big smiles.\n",
      "\n",
      "    Title: Just Debate,\n",
      "    Description: Just Debate - war of the words\n",
      "    An Event of Technical debate.\n",
      "\n",
      "Volunteer work: \n",
      "Certifications: \n",
      "Publications: \n",
      "    Name: Fx Optimiser upto 80% faster Artificial Neural Network Training,\n",
      "    Publisher: OpenReview,\n",
      "    Description: Fx Optimiser is successor to Adam Optimiser.\n",
      "    It is observed to throuput upto 80% faster Artificial Neural Network Training.\n",
      "\n",
      "Honors_awards: \n",
      "    Title: Leadership and Excellence Award,\n",
      "    Issuer: Gujarat Technological University, Ahmedabad, Gujarat, India,\n",
      "    Description: None.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(profile_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_file = \"Turing_ML.json\"\n",
    "filepath = \"Json/job_detail/\"+job_file\n",
    "with open(filepath, 'r') as json_file:\n",
    "    job_data = json.load(json_file)\n",
    "\n",
    "\n",
    "job_description = job_data[\"job_description\"]\n",
    "job_description = textwrap.indent(job_description, \"\\n    \")\n",
    "title = job_data[\"title\"]\n",
    "location = str(job_data[\"location\"][\"city\"]) + \",\" + \\\n",
    "    str(job_data[\"location\"][\"region\"])+\",\" + \\\n",
    "    str(job_data[\"location\"][\"country\"])\n",
    "company = job_data[\"company\"][\"name\"]\n",
    "industry = job_data[\"industry\"][0]\n",
    "employment_type = job_data[\"employment_type\"]\n",
    "job_functions = job_data[\"job_functions\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      " Title: \n",
      "     Remote Machine Learning Engineer Jobs\n",
      "Compnay name: \n",
      "     Turing\n",
      "Location: \n",
      "     None,None,India\n",
      "Industry: \n",
      "     Software Development\n",
      "Job description: \n",
      "    An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "\n",
      "    **Job Responsibilities:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "\n",
      "      * Experiment with ML techniques to create and test new program features\n",
      "\n",
      "      * Assist in extending and improving existing ML frameworks and libraries\n",
      "\n",
      "      * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "\n",
      "      * Integrate ML models to end-users and run experiments\n",
      "\n",
      "      * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "    **Job Requirements:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "\n",
      "      * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "\n",
      "      * Must have hands-on experience in Adaptive Learning Systems \n",
      "\n",
      "      * Should be well versed in MEAN and/or MERN stacks\n",
      "\n",
      "      * Expertise in Machine Learning and Artificial Intelligence \n",
      "\n",
      "      * Experience in data science projects and psychometrics is required\n",
      "\n",
      "      * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "Employment type: \n",
      "     Full-time\n",
      "Job functions: \n",
      "     Engineering and Information Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_details = \"Job details:\\n \"\\\n",
    "    \"Title: \\n     \"+str(title) + \"\\n\"\\\n",
    "    \"Compnay name: \\n     \"+str(company) + \"\\n\"\\\n",
    "    \"Location: \\n     \"+str(location) + \"\\n\"\\\n",
    "    \"Industry: \\n     \"+str(industry) + \"\\n\"\\\n",
    "    \"Job description: \"+str(job_description) + \"\\n\"\\\n",
    "    \"Employment type: \\n     \"+str(employment_type) + \"\\n\"\\\n",
    "    \"Job functions: \\n     \"+str(job_functions) + \"\\n\"\n",
    "print(job_details)\n",
    "# job_details = textwrap.indent(job_details, \"    \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      " Title: \n",
      "     Remote Machine Learning Engineer Jobs\n",
      "Compnay name: \n",
      "     Turing\n",
      "Location: \n",
      "     None,None,India\n",
      "Industry: \n",
      "     Software Development\n",
      "Job description: \n",
      "    An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "\n",
      "    **Job Responsibilities:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "\n",
      "      * Experiment with ML techniques to create and test new program features\n",
      "\n",
      "      * Assist in extending and improving existing ML frameworks and libraries\n",
      "\n",
      "      * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "\n",
      "      * Integrate ML models to end-users and run experiments\n",
      "\n",
      "      * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "    **Job Requirements:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "\n",
      "      * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "\n",
      "      * Must have hands-on experience in Adaptive Learning Systems \n",
      "\n",
      "      * Should be well versed in MEAN and/or MERN stacks\n",
      "\n",
      "      * Expertise in Machine Learning and Artificial Intelligence \n",
      "\n",
      "      * Experience in data science projects and psychometrics is required\n",
      "\n",
      "      * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "Employment type: \n",
      "     Full-time\n",
      "Job functions: \n",
      "     Engineering and Information Technology\n",
      "\n",
      " Profile details:\n",
      "Name: \n",
      "     Hemen Ashodia\n",
      "Occupation: \n",
      "     Founder / Chief Scientist at F(x) Data Labs PVT LTD\n",
      "Email: \n",
      "     hemen@htree.plus\n",
      "Summary: \n",
      "     To invent.\n",
      "Country: \n",
      "     India\n",
      "City: \n",
      "     Ahmedabad\n",
      "State: \n",
      "     Gujarat\n",
      "Languages: \n",
      "    English, Gujarati, Hindi\n",
      "Skills: \n",
      "    agile methodologies, ajax, algorithm design, artificial intelligence, artificial neural networks, business strategy, c, c++, core java, css, css3, data science, data structures, design patterns, event management, facebook api, facebook open graph protocols, gamification, html, html 5, html5, j2se, java, javascript, jquery, json, linux, machine learning, magento, marketing strategy, mysql, natural language processing, node.js, parallax, php, poetry, product design, programming, python, risk management, semantic web, seo, software development, start ups, venture development, web applications, web development, web services, zend framework\n",
      "Experiences: \n",
      "    starts at: 2018-11-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: Medlex.ai,\n",
      "    Title: Machine Learning Developer,\n",
      "    description: None,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2015-03-01T00:00:00Z,\n",
      "    Ends at: 2015-07-31T00:00:00Z,\n",
      "    Company: Zidisha,\n",
      "    Title: Chief Technology Officer,\n",
      "    description: Zidisha is the first online microlending community that directly connects lenders and borrowers — no matter the distance or disparity between them.\n",
      "\n",
      "    More than 200,000 people worldwide have started using Zidisha.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2013-05-01T00:00:00Z,\n",
      "    Ends at: 2015-02-28T00:00:00Z,\n",
      "    Company: Remarkin.com,\n",
      "    Title: Founder / CEO,\n",
      "    description: Remarkin.com is a start-up venture aims to make education easy, engaging and creative.,\n",
      "    location: Ahmedabad.\n",
      "\n",
      "    starts at: 2013-03-01T00:00:00Z,\n",
      "    Ends at: 2015-02-28T00:00:00Z,\n",
      "    Company: Venture Design Fellow,\n",
      "    Title: Venture Studio,\n",
      "    description: Venture Studio program follows a design methodology based from research conducted in the field of engineering and product innovation. The program is run by Ahmedabad University in Collaboration with Center for Design Research at Stanford University,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-07-01T00:00:00Z,\n",
      "    Ends at: 2013-04-30T00:00:00Z,\n",
      "    Company: Aspire Institute,\n",
      "    Title: Trainer/ faculty,\n",
      "    description: Coaching for Advance web development with PHP,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2012-07-01T00:00:00Z,\n",
      "    Ends at: 2012-10-31T00:00:00Z,\n",
      "    Company: Vox Populi Club,\n",
      "    Title: Tech-Event Manager,\n",
      "    description: VP-club is club in L.D. College of Engineering, Ahmedabad.\n",
      "    that organizes events to keep Engineers Beating ..:),\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-01-01T00:00:00Z,\n",
      "    Ends at: 2012-12-31T00:00:00Z,\n",
      "    Company: Vox Populi Magazine,\n",
      "    Title: Techtonic,\n",
      "    description: Working for tech department of Vox-Populi Magazine.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2012-01-01T00:00:00Z,\n",
      "    Ends at: 2012-11-30T00:00:00Z,\n",
      "    Company: Vox Populi Club,\n",
      "    Title: Manager OF Technical Events,\n",
      "    description: I work as a Technical Event manger at Vox Populi Club\n",
      "    In LD College of Engineering Ahmedabad,\n",
      "    location: Ahmedabad.\n",
      "\n",
      "    starts at: 2011-08-01T00:00:00Z,\n",
      "    Ends at: 2012-04-30T00:00:00Z,\n",
      "    Company: Topupchat.com,\n",
      "    Title: CEO/founder,\n",
      "    description: As a CEO I invent all new feature of this website topupchat.com,\n",
      "    the entire idea, code and design of this website is designed and invented by me,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-03-01T00:00:00Z,\n",
      "    Ends at: 2019-12-31T00:00:00Z,\n",
      "    Company: ArtuData,\n",
      "    Title: Chief Data Scientist,\n",
      "    description: 80% of your profit is generated by just 2% of your visitors\n",
      "    ArtuData empowers your marketing and sales teams to identify leads in real-time, giving each team full focus to convert them into paying customers. Now you can boost your efficiency and ROI while reducing your cost per acquisition.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Johnson & Johnson,\n",
      "    Title: Lead Data Scientist and Machine Learning Expert,\n",
      "    description: Worked as a Lead Data Scientist and Machine Learning Expert at Johnson & Johnson - Data Science.\n",
      "    Created data pipelines, which used millions of data points, for the identification of the best strategies to increase the effectiveness of professional educational events.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Loom Network,\n",
      "    Title: Lead Go Developer,\n",
      "    description: Built a Karma system for a decentralized crypto platform and implemented a Sparse Merkle Tree.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2018-01-01T00:00:00Z,\n",
      "    Ends at: 2018-12-31T00:00:00Z,\n",
      "    Company: Paravision,\n",
      "    Title: TensorFlow Expert,\n",
      "    description: Invented the fastest algorithm to identify the correct face using machine learning with a 99.81% accuracy.,\n",
      "    location: None.\n",
      "\n",
      "    starts at: 2015-08-01T00:00:00Z,\n",
      "    Ends at: None,\n",
      "    Company: F(x) Data Labs PVT LTD,\n",
      "    Title: Founder / Chief Scientist,\n",
      "    description: At F(x) Data Labs, we are working on our algorithm called h+tree which increases the speed limit of the databases that serves more number of users at a time.\n",
      "\n",
      "     h+ tree is capable to deliver 300% speed compared to the existing B+Tree. Hence your servers will become exceptionally fast and your server cost also goes down eventually.\n",
      "\n",
      "    The end goal for setting up our cloud infrastructure is that we want to inject our h+Tree algorithm into our cloud servers and we look forward to delivering the fastest cloud servers to the entire software industry!,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "    starts at: 2012-05-01T00:00:00Z,\n",
      "    Ends at: 2012-07-31T00:00:00Z,\n",
      "    Company: Amitech,\n",
      "    Title: Web Developer,\n",
      "    description: Worked as Facebook Application Developer and Firefox Extension Developer at Amitech.\n",
      "    Amitech is a software solution company from Ahmedabad.,\n",
      "    location: Ahmedabad Area, India.\n",
      "\n",
      "Education: \n",
      "    Starts at: 2013-01-01T00:00:00Z,\n",
      "    Ends at: 2015-12-31T00:00:00Z,\n",
      "    Field of study: Entrepreneurship and Design Thinking,\n",
      "    Degree name: Fellowship,\n",
      "    School: VentureStudio Partnered with Stanford University, California.\n",
      "\n",
      "    Starts at: 2010-01-01T00:00:00Z,\n",
      "    Ends at: 2014-12-31T00:00:00Z,\n",
      "    Field of study: IT,\n",
      "    Degree name: BE,\n",
      "    School: L.D College of Engineering - Ahmedabad.\n",
      "\n",
      "    Starts at: 2003-01-01T00:00:00Z,\n",
      "    Ends at: 2010-12-31T00:00:00Z,\n",
      "    Field of study: Science,\n",
      "    Degree name: 12th,\n",
      "    School: V. D. High School, Bhuj-Kutch.\n",
      "\n",
      "Accomplishment organisations: \n",
      "Projects: \n",
      "    Title: Topupchat.com(Free Recharge),\n",
      "    Description: Chat with your fiends and get free Mobile Recharge.\n",
      "\n",
      "    Title: Net Meeting,\n",
      "    Description: A portal for easy virtual meeting..\n",
      "\n",
      "    Title: ICATES2013,\n",
      "    Description: A responsive website for an International Conference on Advances in Tribology and Engineering Systems.\n",
      "\n",
      "    Title: MN Framework,\n",
      "    Description: An extremely robust and easy to use framework of highly distributed development of Advance PHP web projects.\n",
      "    Helpful for beginners - intermediates and experts.\n",
      "\n",
      "    Title: LGD Library,\n",
      "    Description: Layered image processing library for PHP.\n",
      "\n",
      "    Title: Me Famous,\n",
      "    Description: an app to update fb status in a stylish way.\n",
      "\n",
      "    Title: PicInChat.com,\n",
      "    Description: upload & Send pic to facebook friends in chat as big smiles.\n",
      "\n",
      "    Title: Just Debate,\n",
      "    Description: Just Debate - war of the words\n",
      "    An Event of Technical debate.\n",
      "\n",
      "Volunteer work: \n",
      "Certifications: \n",
      "Publications: \n",
      "    Name: Fx Optimiser upto 80% faster Artificial Neural Network Training,\n",
      "    Publisher: OpenReview,\n",
      "    Description: Fx Optimiser is successor to Adam Optimiser.\n",
      "    It is observed to throuput upto 80% faster Artificial Neural Network Training.\n",
      "\n",
      "Honors_awards: \n",
      "    Title: Leadership and Excellence Award,\n",
      "    Issuer: Gujarat Technological University, Ahmedabad, Gujarat, India,\n",
      "    Description: None.\n",
      "\n",
      "\n",
      "Write 500 words of a classic job cover letter for provided profile details if job application is done for the above mention job details\n"
     ]
    }
   ],
   "source": [
    "# job_details = \"Job details:\\n \"\n",
    "gpt_prompt = job_details + \"\\n \"+profile_details + \\\n",
    "    \"\\nWrite 500 words of a classic job cover letter for provided profile details if job application is done for the above mention job details\"\n",
    "print(gpt_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-W9GGK***************************************tbP8. You can find your API key at https://beta.openai.com.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-8b1de3b1187c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpt_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             return (\n\u001b[0;32m--> 599\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    600\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 ),\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-W9GGK***************************************tbP8. You can find your API key at https://beta.openai.com."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "# gpt_prompt = \"I have to create a cover letter for me so can you wait for my secound request\"\n",
    "secound_prompt = profile_details + \\\n",
    "    \" this is a profile details. wait for my next request\"\n",
    "third_prompt = job_details + \\\n",
    "    \" this is a job details. wait for my next request\"\n",
    "forth_prompt = \"Can You create a cover letter for maction above profile details and job det\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=gpt_prompt,\n",
    "    temperature=0.99,\n",
    "    max_tokens=2048,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.3,\n",
    "    presence_penalty=0.9,\n",
    "    stop=[\"Job details:\", \"Profile details:\"]\n",
    ")\n",
    "print(\"----------------cover letter----------------------\")\n",
    "result = response['choices'][0]['text']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'experiences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-d36e9a2491ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtodays_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"I have total\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"experiences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'experiences'"
     ]
    }
   ],
   "source": [
    "data[\"experiences\"]\n",
    "todays_date = date.today()\n",
    "experiences=\"I have total\"\n",
    "for j in range(len(data[\"experiences\"])):\n",
    "    # print(j)\n",
    "    if j==0:\n",
    "        \n",
    "        start_date = str(data[\"experiences\"][j]['starts_at']['year'])+\"-\" + str(data[\"experiences\"]\n",
    "                                                                                [j]['starts_at']['month']) + \"-\" + str(data[\"experiences\"][j]['starts_at']['day'])\n",
    "        end_date = str(todays_date.year) + \"-\" + str(todays_date.month)+\"-\"+str(todays_date.day)\n",
    "        start_date_object = datetime.strptime(str(start_date), \"%Y-%m-%d\")\n",
    "        end_date_object = datetime.strptime(str(end_date), \"%Y-%m-%d\")\n",
    "        total_days = (end_date_object - start_date_object).days\n",
    "\n",
    "        data[\"experiences\"][0]['ends_at'] = todays_date.year\n",
    "        # total_experiences = total_days/365\n",
    "\n",
    "        total_experiences = int(data[\"experiences\"][0]['ends_at']) - int(\n",
    "            data[\"experiences\"][len(data[\"experiences\"])-1]['ends_at']['year'])\n",
    "        experiences += \" \" + str(round(total_experiences,1)) + \" Years of experiences.\"\n",
    "\n",
    "\n",
    "        if total_days > 363:\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_year = total_days/363\n",
    "            each_experiences += \"\" + str(round(each_year, 1)) + \" years of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \".\"\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "        else:\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_month = int(total_days/12)\n",
    "            each_experiences += \"\" + str(each_month) + \" months of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \".\"\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "\n",
    "\n",
    "        # print(experiences)\n",
    "\n",
    "    else:\n",
    "        # print(j)\n",
    "        start_date = str(data[\"experiences\"][j]['starts_at']['year'])+\"-\"+ str(data[\"experiences\"][j]['starts_at']['month']) + \"-\"+ str(data[\"experiences\"][j]['starts_at']['day'])\n",
    "        end_date = str(data[\"experiences\"][j]['ends_at']['year']) + \"-\"+str(data[\"experiences\"][j]['ends_at']['month']) + \"-\"+ str(data[\"experiences\"][j]['ends_at']['day'])\n",
    "        start_date_object = datetime.strptime(str(start_date), \"%Y-%m-%d\")\n",
    "        end_date_object = datetime.strptime(str(end_date), \"%Y-%m-%d\")\n",
    "        total_days = (end_date_object - start_date_object).days\n",
    "        # print(total_days)\n",
    "        if total_days > 363:\n",
    "            # print(total_days)\n",
    "            each_experiences=\"In which i have \"\n",
    "            # print(total_days)\n",
    "            each_year = total_days/360\n",
    "            each_experiences += \"\" + str(round(each_year, 1)) + \" years of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + str(\n",
    "                    data[\"experiences\"][j]['title']) + \", and \" + data[\"experiences\"][j]['description']\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "    \n",
    "        else :\n",
    "            # print(\"totaldays==\",total_days)\n",
    "            each_experiences = \"In which i have \"\n",
    "            # print(\"total_days/12==\", total_days/12)\n",
    "            each_month = int(total_days/30)\n",
    "            # print(each_month)\n",
    "            each_experiences += \"\" + str(each_month) + \" months of experience at \" + \\\n",
    "                str(data[\"experiences\"][j]['company']) + \" and my role is \" + \\\n",
    "                str(data[\"experiences\"][j]['title']) + \", and \" + \\\n",
    "                data[\"experiences\"][j]['description']\n",
    "            # print(each_experiences)\n",
    "            experiences += each_experiences\n",
    "    print(experiences)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>\n",
      "\n",
      "\n",
      "Hi Vivek, nice to meet you!\n",
      "\n",
      ">>\n",
      " \n",
      "\n",
      "That's great! It sounds like you have the skills to develop a variety of applications and programs.\n",
      "\n",
      ">>\n",
      " in programming\n",
      "\n",
      "That's wonderful! It sounds like you have a lot of valuable experience that could be beneficial for many projects.\n",
      "\n",
      ">>\n",
      " ?\n",
      "\n",
      "Yes, I can create a cover letter for you to apply with Google.  Please provide me with more details about yourself and the position that you are interested in, so I can tailor the letter to best demonstrate your qualifications.\n",
      "\n",
      ">>\n",
      " field\n",
      "\n",
      "That's great to hear! It sounds like Machine Learning is an area that you find interesting. Please let me know what it is about Machine Learning that you find interesting and I can provide more information on the topic if needed.\n",
      "\n",
      ">>\n",
      "\n",
      "\n",
      "That is great! It sounds like you had a high GPA which is an excellent foundation for your work in the Machine Learning field. Have you had any experience with the technology yet? If not, I can provide some resources to help you get started.\n",
      "\n",
      ">>\n",
      " ?\n",
      "\n",
      "Yes, of course! Please provide me with any information you have about the position you are applying for and your work experience. I will then use this information to create a cover letter that best demonstrates your skills and qualifications.\n",
      "\n",
      ">>\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5732 tokens (3684 in your prompt; 2048 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-189cfba1373b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Sends the prompt and context to the OpenAI API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"context:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"prompt:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             return (\n\u001b[0;32m--> 599\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    600\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 ),\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5732 tokens (3684 in your prompt; 2048 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "#test \n",
    "\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "\n",
    "# Setting the API key to use the OpenAI API\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Setting up the logging feature by creating a file with the topic name\n",
    "topic = \"demo\"\n",
    "history_log = 'history/' + re.sub('[^0-9a-zA-Z]+', '', topic) + '.log'\n",
    "file = open(history_log, \"a\")\n",
    "\n",
    "# Initializing the prompt and context variables\n",
    "prompt = \"\"\n",
    "context = \"\"\n",
    "\n",
    "while True:\n",
    "    # Prints '>>' to indicate user input is needed\n",
    "    print(\">>\")\n",
    "    # User input for the prompt\n",
    "    prompt = input()\n",
    "    # If the user inputs 'exit', the loop breaks\n",
    "    if prompt == 'exit':\n",
    "        break\n",
    "    # Writes the user's input to the log file\n",
    "    file.write(prompt)\n",
    "    # Sends the prompt and context to the OpenAI API\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"context:\" + context + \"\\n\\n\" + \"prompt:\" + prompt,\n",
    "        temperature=0.99,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.3,\n",
    "        presence_penalty=0.9\n",
    "    )\n",
    "    # Writes the API's response to the log file\n",
    "    file.write(response[\"choices\"][0][\"text\"] + \"\\n\")\n",
    "    # Prints the API's response\n",
    "    print(response[\"choices\"][0][\"text\"] + \"\\n\")\n",
    "    # Adds the prompt and response to the context variable\n",
    "    context += \"\\n\".join([context, prompt, response[\"choices\"][0][\"text\"]])\n",
    "\n",
    "# Closes the log file\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Job details:\n",
      " Title: \n",
      "     Remote Machine Learning Engineer Jobs\n",
      "Compnay name: \n",
      "     Turing\n",
      "Location: \n",
      "     None,None,India\n",
      "Industry: \n",
      "     Software Development\n",
      "Job description: \n",
      "    An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "\n",
      "    **Job Responsibilities:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "\n",
      "      * Experiment with ML techniques to create and test new program features\n",
      "\n",
      "      * Assist in extending and improving existing ML frameworks and libraries\n",
      "\n",
      "      * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "\n",
      "      * Integrate ML models to end-users and run experiments\n",
      "\n",
      "      * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "    **Job Requirements:**\n",
      "  \n",
      "\n",
      "\n",
      "      * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "\n",
      "      * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "\n",
      "      * Must have hands-on experience in Adaptive Learning Systems \n",
      "\n",
      "      * Should be well versed in MEAN and/or MERN stacks\n",
      "\n",
      "      * Expertise in Machine Learning and Artificial Intelligence \n",
      "\n",
      "      * Experience in data science projects and psychometrics is required\n",
      "\n",
      "      * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "Employment type: \n",
      "     Full-time\n",
      "Job functions: \n",
      "     Engineering and Information Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_filepath = \"Json/job_detail/Turing_ML.json\"\n",
    "with open(job_filepath, 'r') as json_file:\n",
    "    job_data = json.load(json_file)\n",
    "\n",
    "linkedindata = \"random.json\"\n",
    "filepath = \"Json/New data/\"+linkedindata\n",
    "with open(filepath, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "# for skills\n",
    "skills = \"\"\n",
    "for i in range(len(data[\"data\"][\"skills\"])):\n",
    "    skills_data = data[\"data\"][\"skills\"][i]\n",
    "    if i == 0:\n",
    "        skills += \"\\n\" + skills_data\n",
    "    else:\n",
    "        skills += \", \" + skills_data\n",
    "skills = textwrap.indent(skills, \"    \")\n",
    "\n",
    "\n",
    "# for languages\n",
    "languages = \"\"\n",
    "for i in range(len(data[\"data\"][\"languages\"])):\n",
    "    languages_data = data[\"data\"][\"languages\"][i]\n",
    "    if i == 0:\n",
    "        languages += \"\\n\" + languages_data\n",
    "    else:\n",
    "        languages += \", \" + languages_data\n",
    "\n",
    "languages = textwrap.indent(languages, \"    \")\n",
    "\n",
    "# for user_experiences\n",
    "user_experiences = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"user_experiences\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['ends_at']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['company']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['description']\n",
    "    location = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"][j]['location']\n",
    "\n",
    "    user_experiences_data = \"starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"Company: \"+str(company) +\\\n",
    "        \",\\n\"\"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"description: \"+str(description) +\\\n",
    "        \",\\n\"\"location: \"+str(location)+\".\\n\"\n",
    "\n",
    "    # print(user_experiences)\n",
    "    user_experiences += \"\\n\"+user_experiences_data\n",
    "\n",
    "user_experiences = textwrap.indent(user_experiences, \"    \")\n",
    "\n",
    "# for usereducation\n",
    "usereducation = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usereducation\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['ends_at']\n",
    "    field_of_study = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['field_of_study']\n",
    "    degree_name = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['degree_name']\n",
    "    school = data[\"data\"][\"user_carrier_data\"][\"usereducation\"][j]['school']\n",
    "\n",
    "    usereducation_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\nEnds at: \"+str(ends_at) +\\\n",
    "        \",\\nField of study: \"+str(field_of_study) +\\\n",
    "        \",\\nDegree name: \"+str(degree_name) +\\\n",
    "        \",\\nSchool: \"+str(school) + \".\\n\"\n",
    "\n",
    "    # print(usereducation)\n",
    "    usereducation += \"\\n\"+usereducation_data\n",
    "\n",
    "usereducation = textwrap.indent(usereducation, \"    \")\n",
    "\n",
    "# for useraccomplishmentorganisations\n",
    "useraccomplishmentorganisations = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"])):\n",
    "    org_name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['org_name']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentorganisations\"][j]['description']\n",
    "\n",
    "    useraccomplishmentorganisations_data = \"Organisation name: \"+str(org_name) +\\\n",
    "        \",\\nTitle: \"+str(title) +\\\n",
    "        \",\\nDescription: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentorganisations)\n",
    "    useraccomplishmentorganisations += \"\\n\"+useraccomplishmentorganisations_data\n",
    "\n",
    "useraccomplishmentorganisations = textwrap.indent(\n",
    "    useraccomplishmentorganisations, \"    \")\n",
    "\n",
    "# for useraccomplishmentprojects\n",
    "useraccomplishmentprojects = \"\"\n",
    "print(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]))\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"][j]['description']\n",
    "\n",
    "    useraccomplishmentprojects_data = \"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    useraccomplishmentprojects += \"\\n\"+useraccomplishmentprojects_data\n",
    "\n",
    "\n",
    "useraccomplishmentprojects = textwrap.indent(\n",
    "    useraccomplishmentprojects, \"    \")\n",
    "\n",
    "# for uservolunteerwork\n",
    "uservolunteerwork = \"\"\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['starts_at']\n",
    "    ends_at = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['ends_at']\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['title']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['description']\n",
    "    cause = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['cause']\n",
    "    company = data[\"data\"][\"user_carrier_data\"][\"uservolunteerwork\"][j]['company']\n",
    "\n",
    "    uservolunteerwork_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Ends at: \"+str(ends_at) +\\\n",
    "        \",\\n\"\"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) +\\\n",
    "        \",\\n\"\"Cause: \"+str(cause) +\\\n",
    "        \",\\n\"\"Company: \"+str(company) + \".\\n\"\n",
    "\n",
    "    # print(uservolunteerwork)\n",
    "    uservolunteerwork += \"\\n\"+uservolunteerwork_data\n",
    "\n",
    "uservolunteerwork = textwrap.indent(\n",
    "    uservolunteerwork, \"    \")\n",
    "\n",
    "# for usercertifications\n",
    "usercertifications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"usercertifications\"])):\n",
    "    starts_at = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['starts_at']\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['name']\n",
    "    authority = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"][j]['authority']\n",
    "\n",
    "    usercertifications_data = \"Starts at: \"+str(starts_at) +\\\n",
    "        \",\\n\"\"Name: \"+str(name) +\\\n",
    "        \",\\n\"\"Authority: \"+str(authority) + \".\\n\"\n",
    "\n",
    "    # print(usercertifications)\n",
    "    usercertifications += \"\\n\"+usercertifications_data\n",
    "usercertifications = textwrap.indent(\n",
    "    usercertifications, \"    \")\n",
    "\n",
    "# for useraccomplishmentpublications\n",
    "useraccomplishmentpublications = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"])):\n",
    "    name = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['name']\n",
    "    publisher = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['publisher']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentpublications\"][j]['description']\n",
    "\n",
    "    useraccomplishmentpublications_data = \"Name: \"+str(name) +\\\n",
    "        \",\\n\"\"Publisher: \"+str(publisher) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmentpublications)\n",
    "    useraccomplishmentpublications += \"\\n\"+useraccomplishmentpublications_data\n",
    "useraccomplishmentpublications = textwrap.indent(\n",
    "    useraccomplishmentpublications, \"    \")\n",
    "\n",
    "# for useraccomplishmenthonorsawards\n",
    "useraccomplishmenthonorsawards = \"\"\n",
    "\n",
    "for j in range(len(data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"])):\n",
    "    title = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['title']\n",
    "    issuer = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['issuer']\n",
    "    description = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmenthonorsawards\"][j]['description']\n",
    "\n",
    "    useraccomplishmenthonorsawards_data = \"Title: \"+str(title) +\\\n",
    "        \",\\n\"\"Issuer: \"+str(issuer) +\\\n",
    "        \",\\n\"\"Description: \"+str(description) + \".\\n\"\n",
    "\n",
    "    # print(useraccomplishmenthonorsawards)\n",
    "    useraccomplishmenthonorsawards += \"\\n\"+useraccomplishmenthonorsawards_data\n",
    "useraccomplishmenthonorsawards = textwrap.indent(\n",
    "    useraccomplishmenthonorsawards, \"    \")\n",
    "\n",
    "\n",
    "First_name = str(data[\"data\"][\"first_name\"])\n",
    "last_name = data[\"data\"][\"last_name\"]\n",
    "Occupation = data[\"data\"][\"occupation\"]\n",
    "Email = data[\"data\"][\"email\"]\n",
    "Summary = data[\"data\"][\"summary\"]\n",
    "Country_full_name = data[\"data\"][\"country_full_name\"]\n",
    "City = data[\"data\"][\"city\"]\n",
    "state = data[\"data\"][\"state\"]\n",
    "# Languages = data[\"data\"][\"languages\"]\n",
    "Languages = languages\n",
    "# skills = data[\"data\"][\"skills\"]\n",
    "skills = skills\n",
    "\n",
    "# User_experiences = data[\"data\"][\"user_carrier_data\"][\"user_experiences\"]\n",
    "User_experiences = user_experiences\n",
    "\n",
    "# User_education = data[\"data\"][\"user_carrier_data\"][\"usereducation\"]\n",
    "User_education = usereducation\n",
    "\n",
    "# User_accomplishment_organisations = data[\"data\"][\n",
    "# \"user_carrier_data\"][\"useraccomplishmentorganisations\"]\n",
    "User_accomplishment_organisations = useraccomplishmentorganisations\n",
    "\n",
    "# User_accomplishment_projects = data[\"data\"][\"user_carrier_data\"][\"useraccomplishmentprojects\"]\n",
    "User_accomplishment_projects = useraccomplishmentprojects\n",
    "\n",
    "# User_volunteer_work = User_certifications = data[\n",
    "#     \"data\"][\"user_carrier_data\"][\"uservolunteerwork\"]\n",
    "User_volunteer_work = uservolunteerwork\n",
    "\n",
    "# User_certifications = data[\"data\"][\"user_carrier_data\"][\"usercertifications\"]\n",
    "User_certifications = usercertifications\n",
    "\n",
    "# User_accomplishment_publications = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmentpublications\"]\n",
    "User_accomplishment_publications = useraccomplishmentpublications\n",
    "\n",
    "# User_accomplishment_honors_awards = data[\"data\"][\n",
    "#     \"user_carrier_data\"][\"useraccomplishmenthonorsawards\"]\n",
    "User_accomplishment_honors_awards = useraccomplishmenthonorsawards\n",
    "\n",
    "\n",
    "job_description = job_data[\"job_description\"]\n",
    "job_description = textwrap.indent(job_description, \"\\n    \")\n",
    "title = job_data[\"title\"]\n",
    "location = str(job_data[\"location\"][\"city\"]) + \",\" + \\\n",
    "    str(job_data[\"location\"][\"region\"])+\",\" + \\\n",
    "    str(job_data[\"location\"][\"country\"])\n",
    "company = job_data[\"company\"][\"name\"]\n",
    "industry = job_data[\"industry\"][0]\n",
    "employment_type = job_data[\"employment_type\"]\n",
    "job_functions = job_data[\"job_functions\"][0]\n",
    "\n",
    "profile_details = \"Profile details:\\n\" \\\n",
    "    \"Name: \\n     \"+str(First_name) + \" \"+str(last_name) + \"\\n\"\\\n",
    "    \"Occupation: \\n     \"+str(Occupation) + \"\\n\"\\\n",
    "    \"Email: \\n     \"+str(Email) + \"\\n\"\\\n",
    "    \"Summary: \\n     \"+str(Summary) + \"\\n\"\\\n",
    "    \"Country: \\n     \"+str(Country_full_name) + \"\\n\"\\\n",
    "    \"City: \\n     \"+str(City) + \"\\n\"\\\n",
    "    \"State: \\n     \"+str(state) + \"\\n\"\\\n",
    "    \"Languages: \"+str(Languages) + \"\\n\"\\\n",
    "    \"Skills: \"+str(skills) + \"\\n\"\\\n",
    "    \"Experiences: \"+str(User_experiences) + \"\\n\"\\\n",
    "    \"Education: \"+str(User_education) + \"\\n\"\\\n",
    "    \"Accomplishment organisations: \"+str(User_accomplishment_organisations) + \"\\n\"\\\n",
    "    \"Projects: \"+str(User_accomplishment_projects) + \"\\n\"\\\n",
    "    \"Volunteer work: \"+str(User_volunteer_work) + \"\\n\"\\\n",
    "    \"Certifications: \"+str(User_certifications) + \"\\n\"\\\n",
    "    \"Publications: \"+str(User_accomplishment_publications) + \"\\n\"\\\n",
    "    \"Honors_awards: \"+str(User_accomplishment_honors_awards) + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "job_details = \"Job details:\\n \"\\\n",
    "    \"Title: \\n     \"+str(title) + \"\\n\"\\\n",
    "    \"Compnay name: \\n     \"+str(company) + \"\\n\"\\\n",
    "    \"Location: \\n     \"+str(location) + \"\\n\"\\\n",
    "    \"Industry: \\n     \"+str(industry) + \"\\n\"\\\n",
    "    \"Job description: \"+str(job_description) + \"\\n\"\\\n",
    "    \"Employment type: \\n     \"+str(employment_type) + \"\\n\"\\\n",
    "    \"Job functions: \\n     \"+str(job_functions) + \"\\n\"\n",
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details:\n",
      "     Title: Remote Machine Learning Engineer Jobs\n",
      "    Compnay name: Turing\n",
      "    Location: None,None,India\n",
      "    Industry: Software Development\n",
      "    Job description: An emerging edtech startup building an initial team of talented individuals is looking for a Machine Learning Engineer. The engineer will be actively contributing to developing a computer adaptive testing solution that also employs machine learning for the education space. The company has recently raised a pre-seed fund and aims to implement an Adaptive Learning System. This would be an exciting opportunity for those who want to work in a fast-paced and customer-first environment. It requires an overlap with PST. \n",
      "  \n",
      "\n",
      "**Job Responsibilities:**\n",
      "  \n",
      "\n",
      "  * Assist in building back-end infrastructure, data pipelines, and ML models for AI-backed products\n",
      "  * Experiment with ML techniques to create and test new program features\n",
      "  * Assist in extending and improving existing ML frameworks and libraries\n",
      "  * Work alongside data engineers to create data and model pipelines, and embed AI and analytics into the business decision processes\n",
      "  * Integrate ML models to end-users and run experiments\n",
      "  * Run tests, perform statistical analysis, interpret test results, and perform tuning and scaling\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "**Job Requirements:**\n",
      "  \n",
      "\n",
      "  * Bachelor's/Master's degree in Engineering, Computer Science (or equivalent experience)\n",
      "  * At least 3+ years of relevant experience as a Machine Learning Engineer\n",
      "  * Must have hands-on experience in Adaptive Learning Systems \n",
      "  * Should be well versed in MEAN and/or MERN stacks\n",
      "  * Expertise in Machine Learning and Artificial Intelligence \n",
      "  * Experience in data science projects and psychometrics is required\n",
      "  * Must have excellent communication skills with proficiency in English\n",
      "\n",
      "\n",
      "\n",
      "    Employment type: Full-time\n",
      "    Job functions: Engineering and Information Technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------cover letter----------------------\n",
      "\n",
      "\n",
      "Dear Turing Hiring Team,\n",
      "\n",
      "I am writing to apply for the position of Remote Machine Learning Engineer at your company, Turing. \n",
      "I believe my profile and experience make me well-suited for this opportunity. As an experienced DLP Architect at i4DM specializing in Machine Learning and Artificial Intelligence, I bring the following qualifications:\n",
      "\n",
      "* Over 3+ years of expertise as a Machine Learning Engineer with proficiency in MEAN and MERN stacks.\n",
      "* Extensive experience in Adaptive Learning Systems and psychometrics.\n",
      "* Proven ability to build back-end infrastructure, data pipelines, and ML models for AI-backed products.\n",
      "* History of integrating ML models to end-users and running experiments.\n",
      "* Skills in developing data and model pipelines, carrying out statistical analysis, test results interpretation, tuning, and scaling.\n",
      "* Excellent communication skills with knowledge of English language. \n",
      "* Immense familiarity working with customer networks regarding sensitive data protection.  capability to write scripts for automation as well as developing C/C++ libraries for serializing data are also keystrengths that add value to my candidacy. \n",
      "\n",
      " My most recent responsibilities at i4DM included developing policies for protecting sensitive data and managing diverse tasks that involved providing technical support with troubleshooting products from component level upwards. In the past five years - since 2012 - I have worked as an Embedded Systems Developer at New York Air Brake followed by another role as Sustaining Engineer while prior to that being employed as an Embedded Systems Developer at Fuel7 - all of which complemented my professional journey as a Cybersecurity Engineer between June 2018 to May 2022 at GM Financial; a venture where I was successfully able to reduce long process time from days/hours to minutes with scripts written in Perl and Python while also assisting associates on customizing ransomware detection policies via tuning existing patterns. \n",
      "\n",
      "Currently enrolled in Tableau 2022: Hands-On Tableau Training For Data Science! certification course and certified in AWS Cloud Practitioner postgraduate program; it gives me immense pleasure that I am also eligible for further validations such as Certified Information Security Manager (CISM), Certified Ethical Hacker (CEH), CVE® Qualified Professional, Cyber Security Technician Certificate Examination (CSET) among many others which reflects my commitment towards ongoing professional development resulting in comprehensive technological prowess over the years coupled by clear customer orientation due to simultaneous involvement within Domains like Aerospace & Defense industries, Environmental Monitoring systems etcetera. \n",
      "\n",
      " With all the richness gleaned from multi-dimensional roles held over two decades plus prior acumen devised through Bachelor's degree in Electronics & Electricals Engineering supporting hands-on capabilities imbedded through research projects conducted on various aspects such as embedded system design testing etcetera – rest assured that I possess significant expertise related to this job requirement combining ethical behavior amongst teammates within Internal/External work environments while simultaneously fetching customer loyalty & satisfaction effectively within target timeframe owing to innovative ideas supplemented by agile methodologies gaining momentum towards realization of organization’s strategic plans/objectives positioning myself optimally amongst peers standing out arch above competition offering business acumen decision making capacities rooted deeply within science & technology powered deliverables conquering roadblocks without fail reaching Definitive goal oriented success winning applauds alike catapulting golden moments across domain specific initiatives undertaken during tenure period pursued until today leading towards inspirational mutating shift toward destination beyond sky’s limit yet exponential excellence within innovation !! \n",
      "\n",
      " If given the chance, I can be all these great qualities together and much more you need in the role of Remote Machine Learning Engineer at Turing. Thank you very much for taking out your valuable time considering my application despite busy schedule Best Regards Jaime Vinay~\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "# gpt_prompt = \"I have to create a cover letter for me so can you wait for my secound request\"\n",
    "# secound_prompt = profile_details + \\\n",
    "#     \" this is a profile details. wait for my next request\"\n",
    "# third_prompt = job_details + \\\n",
    "#     \" this is a job details. wait for my next request\"\n",
    "# forth_prompt = \"Can You classic create a cover letter for mention above profile details and job details\"\n",
    "# ------final corpus starts-------\n",
    "gpt_prompt = job_details + \"\\n \"+profile_details + \\\n",
    "    \"\\nWrite a job professional cover letter for provided profile details if job application is done for the above mention job details\"\n",
    "\n",
    "# ------final corpus ends-----\n",
    "# print(gpt_prompt)\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=gpt_prompt,\n",
    "    temperature=0.99,\n",
    "    max_tokens=2048,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.3,\n",
    "    presence_penalty=0.9,\n",
    "    stop=[\"Job details:\", \"Profile details:\"]\n",
    ")\n",
    "print(\"----------------cover letter----------------------\")\n",
    "result = response['choices'][0]['text']\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
